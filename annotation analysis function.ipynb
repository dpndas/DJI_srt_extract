{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d78d6fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def annotation_analysis(csv_file_path):\n",
    "    def process_csv(file_path):\n",
    "        # Define the column headers\n",
    "        headers = ['frame', 'classid', 'id', 'x1', 'y1', 'width', 'height', 'a', 'b', 'c', 'd']\n",
    "        \n",
    "        # Read the CSV file into a DataFrame and assign the headers\n",
    "        df_in = pd.read_csv(file_path, header=None, names=headers)\n",
    "        \n",
    "        input_directory = os.path.dirname(csv_file_path)\n",
    "\n",
    "        # Find the number of unique frames in the 'frames' column\n",
    "        unique_frames_count = df_in['frame'].nunique()\n",
    "\n",
    "        # Get unique individuals\n",
    "        unique_individuals = df_in[['classid', 'id']].drop_duplicates()\n",
    "\n",
    "        # Remove entries with classid 2 or -1\n",
    "        unique_individuals = unique_individuals[(unique_individuals['classid'] != 2) & (unique_individuals['classid'] != -1)]\n",
    "\n",
    "        # Calculate the total number of unique individuals\n",
    "        total_individuals = len(unique_individuals)\n",
    "        \n",
    "                \n",
    "        # Calculate 'area' column\n",
    "        df_in['area'] = df_in['width'] * df_in['height']\n",
    "        return df_in, unique_frames_count, total_individuals, unique_individuals \n",
    "    \n",
    "\n",
    "\n",
    "    def class_error(df_in):\n",
    "        # Create a new column 'classid_error' and initialize it with 0\n",
    "        df_in['classid_error'] = 0\n",
    "\n",
    "        # Function to update 'classid_error' column based on 'classid' column\n",
    "        def update_classid_error(row):\n",
    "            if row['classid'] == -1:\n",
    "                return 1\n",
    "            else:\n",
    "                return row['classid_error']\n",
    "\n",
    "        # Apply the update_classid_error function to each row\n",
    "        df_in['classid_error'] = df_in.apply(update_classid_error, axis=1)\n",
    "\n",
    "        df_in['classid_error_frame'] = 0\n",
    "\n",
    "        # Find frames with 'classid_error' entry of 1\n",
    "        frames_with_classid_error = df_in[df_in['classid_error'] == 1]['frame'].unique()\n",
    "\n",
    "        # Update 'classid_error_frame' column for the identified frames\n",
    "        df_in.loc[df_in['frame'].isin(frames_with_classid_error), 'classid_error_frame'] = 1\n",
    "        \n",
    "        box_classid_error = df_in['classid_error'].sum()\n",
    "\n",
    "        # Print frames with classid errors\n",
    "        print(\"Frames with classid errors:\", frames_with_classid_error)\n",
    "        \n",
    "        return df_in, frames_with_classid_error, box_classid_error      \n",
    "        \n",
    "        #Finding duplicate frames\n",
    "    def duplicates(df_in):\n",
    "        # Create a new column 'duplicates' indicating if a row is a duplicate\n",
    "        df_in['duplicates'] = df_in.groupby(['frame', 'classid'])['id'].transform(lambda x: x.duplicated(keep=False).astype(int))\n",
    "        duplicate_statements = []\n",
    "        # Find unique frames with duplicates\n",
    "        frames_with_duplicates = df_in.loc[df_in['duplicates'] == 1, 'frame'].unique()\n",
    "        \n",
    "        # Create 'duplicate_frame' column and set values based on 'frame' and 'frames_with_duplicates'\n",
    "        df_in['duplicate_frame'] = df_in['frame'].apply(lambda x: 1 if x in frames_with_duplicates else 0)\n",
    "        \n",
    "        for index, row in df_in[df_in['duplicates'] == 1].iterrows(): \n",
    "            statement = f\"ID {row['id']} (Class {row['classid']}) has duplicates in frame {row['frame']}\"\n",
    "            duplicate_statements.append(statement)\n",
    "\n",
    "\n",
    "        # Print frames with duplicates\n",
    "        print(\"Frames with Duplicates:\", frames_with_duplicates)\n",
    "\n",
    "        return df_in, frames_with_duplicates, duplicate_statements\n",
    "    \n",
    "    def iou(df_in):    \n",
    "            \n",
    "        #intersection over union\n",
    "         # Sort the DataFrame by 'classid', 'id', and 'frame' in ascending order\n",
    "        df_in.sort_values(by=['classid', 'id', 'frame'], inplace=True)\n",
    "\n",
    "        # Create a new column to store the IoU values\n",
    "        df_in['iou'] = 0.0  # Initialize with zeros\n",
    "\n",
    "        # Create a dictionary to store the last bounding box coordinates for each individual within each class\n",
    "        last_bbox_dict = {}\n",
    "\n",
    "        # Iterate through the DataFrame\n",
    "        for index, row in df_in.iterrows():\n",
    "            classid = row['classid']\n",
    "            individual_id = row['id']\n",
    "            frame = row['frame']\n",
    "            x1 = row['x1']\n",
    "            y1 = row['y1']\n",
    "            width = row['width']\n",
    "            height = row['height']\n",
    "\n",
    "            # Check if the individual within a class was present in the previous frame\n",
    "            if (classid, individual_id) in last_bbox_dict:\n",
    "                last_x1, last_y1, last_width, last_height = last_bbox_dict[(classid, individual_id)]\n",
    "\n",
    "                # Calculate the coordinates of the current bounding box\n",
    "                x2 = x1 + width\n",
    "                y2 = y1 + height\n",
    "\n",
    "                # Calculate the coordinates of the last known bounding box\n",
    "                last_x2 = last_x1 + last_width\n",
    "                last_y2 = last_y1 + last_height\n",
    "\n",
    "                # Calculate the intersection coordinates\n",
    "                intersection_x1 = max(x1, last_x1)\n",
    "                intersection_y1 = max(y1, last_y1)\n",
    "                intersection_x2 = min(x2, last_x2)\n",
    "                intersection_y2 = min(y2, last_y2)\n",
    "\n",
    "                # Calculate the areas of the current and last bounding boxes\n",
    "                area_current = (x2 - x1) * (y2 - y1)\n",
    "                area_last = (last_x2 - last_x1) * (last_y2 - last_y1)\n",
    "\n",
    "                # Calculate the area of intersection\n",
    "                area_intersection = max(0, intersection_x2 - intersection_x1) * max(0, intersection_y2 - intersection_y1)\n",
    "\n",
    "                # Calculate the IoU\n",
    "                iou = area_intersection / (area_current + area_last - area_intersection)\n",
    "\n",
    "                # Update the DataFrame with the calculated IoU\n",
    "                df_in.at[index, 'iou'] = iou\n",
    "\n",
    "            # Update the last bounding box coordinates for the individual within the class\n",
    "            last_bbox_dict[(classid, individual_id)] = (x1, y1, width, height)\n",
    "            \n",
    "        #Finding boxes with IOU=0    \n",
    "        row_with_iou_0 = df_in[(df_in['iou'] == 0) & (df_in['frame'] != df_in.groupby(['classid', 'id'])['frame'].transform('min')) & (df_in['classid'] != -1)]\n",
    "\n",
    "        len(row_with_iou_0)\n",
    "\n",
    "        # Initialize an empty list to store sentences\n",
    "        sentences_iou = []\n",
    "\n",
    "        # Iterate through the rows of row_with_iou_0 DataFrame\n",
    "        for index, row in row_with_iou_0.iterrows():\n",
    "            classid = row['classid']\n",
    "            id_value = row['id']\n",
    "            frame_start = row['frame']\n",
    "            frame_end = frame_start - 1  # Subtract 1 from frame_start\n",
    "\n",
    "            # Create the sentence in the desired format\n",
    "            sentence_iou = f'ID {id_value} (Class {classid}) has IOU value 0 between the frames {frame_end} and {frame_start}'\n",
    "\n",
    "\n",
    "            # Append the sentence to the list\n",
    "            sentences_iou.append(sentence_iou)\n",
    "\n",
    "        # Print the sentences or save them as needed\n",
    "        for sentence_iou in sentences_iou:\n",
    "            print(sentence_iou)         \n",
    "        return df_in, sentences_iou, row_with_iou_0\n",
    "\n",
    "   \n",
    "\n",
    "    def disappearing_boxes(df_in, frames_with_classid_error, frames_with_duplicates):\n",
    "        # Sort the DataFrame by 'id' and 'frame' in ascending order\n",
    "        df_in.sort_values(by=['id', 'frame'], inplace=True)\n",
    "\n",
    "        # Create a dictionary to store the last frame for each individual\n",
    "        last_frame_dict = {}\n",
    "        disappearance_statements = []  # Initialize a list to store disappearance statements\n",
    "\n",
    "        # Iterate through the DataFrame\n",
    "        for index, row in df_in.iterrows():\n",
    "            classid = row['classid']\n",
    "            individual_id = row['id']\n",
    "            frame = row['frame']\n",
    "\n",
    "            # Check if the individual was present in the previous frame\n",
    "            if (classid, individual_id) in last_frame_dict:\n",
    "                last_frame = last_frame_dict[(classid, individual_id)]\n",
    "\n",
    "                if frame != last_frame + 1:\n",
    "                    statement = f\"ID {individual_id} (Class {classid}) disappeared in frame {last_frame} and reappeared in frame {frame}\"\n",
    "                    disappearance_statements.append(statement)  # Collect the statements\n",
    "\n",
    "            # Update the last frame for the individual\n",
    "            last_frame_dict[(classid, individual_id)] = frame\n",
    "\n",
    "        # Create a new list without entries containing 'Class -1' and not having one less of the numbers stored in 'frames_with_classid_error'\n",
    "        filtered_disappearance_statements = [\n",
    "            statement for statement in disappearance_statements \n",
    "            if 'Class -1' not in statement \n",
    "            and all(f\"frame {frame - 1}\" not in statement for frame in frames_with_classid_error)\n",
    "            and all(f\"frame {frame}\" not in statement for frame in frames_with_duplicates)\n",
    "        ]\n",
    "\n",
    "        return filtered_disappearance_statements\n",
    "\n",
    "\n",
    "    def plot1(df_in):\n",
    "        def calculate_percentile(df, column, percentile):\n",
    "            df = df.sort_values(by=column)\n",
    "            index = (len(df) - 1) * percentile\n",
    "            floor_index = math.floor(index)\n",
    "            ceil_index = math.ceil(index)\n",
    "            if floor_index == ceil_index:\n",
    "                return df.iloc[int(index)][column]\n",
    "            else:\n",
    "                floor_value = df.iloc[floor_index][column] \n",
    "                ceil_value = df.iloc[ceil_index][column]\n",
    "                return floor_value + (ceil_value - floor_value) * (index - floor_index)\n",
    "\n",
    "        # Filter the DataFrame to exclude rows where 'classid' is 2\n",
    "        df_area_filtered = df_in[df_in['classid'] != 2]\n",
    "\n",
    "        # Calculate the frequency of each area value\n",
    "        area_counts = df_area_filtered['area'].value_counts().sort_index()\n",
    "\n",
    "        # Extract area values and their frequencies\n",
    "        area_values = area_counts.index\n",
    "        frequencies = area_counts.values\n",
    "\n",
    "        # Calculate the mean area\n",
    "        mean_area = df_area_filtered['area'].mean()\n",
    "\n",
    "        # Calculate the standard deviation of the area values\n",
    "        std_dev_area = round(df_area_filtered['area'].std(), 3)\n",
    "\n",
    "        # Calculate the values for mean + standard deviation and mean - standard deviation\n",
    "        mean_plus_std = mean_area + std_dev_area\n",
    "        mean_minus_std = mean_area - std_dev_area\n",
    "\n",
    "        # Calculate the values for mean + 2*standard deviation and mean - 2*standard deviation\n",
    "        mean_plus_2std = mean_area + 2 * std_dev_area\n",
    "        mean_minus_2std = mean_area - 2 * std_dev_area\n",
    "\n",
    "        # Finding the 95th percentile\n",
    "        percentile = calculate_percentile(df_in, 'area', 0.95)\n",
    "\n",
    "        # Create a scatter plot with green color\n",
    "        plt.figure(figsize=(15, 11))  # Reduced figure size\n",
    "        plt.scatter(area_values, frequencies, color=\"green\", marker='o', s=12)\n",
    "        plt.xlabel('Area')\n",
    "        plt.ylabel('No of bounding boxes')\n",
    "        plt.title('Scatter Plot of Bounding Box Areas')\n",
    "        plt.grid()\n",
    "\n",
    "        # Set the X-axis range to the minimum and maximum area values\n",
    "        plt.xlim(min(area_values), max(area_values))\n",
    "\n",
    "        # Annotate the plot with the lowest and highest area values\n",
    "        plt.annotate(f'Min Area: {min(area_values)}', xy=(0.75, 0.95), xycoords='axes fraction', color='black', fontsize=12)\n",
    "        plt.annotate(f'Max Area: {max(area_values)}', xy=(0.75, 0.9), xycoords='axes fraction', color='black', fontsize=12)\n",
    "        plt.annotate(f'μ = Mean Area: {mean_area:.2f}', xy=(0.75, 0.85), xycoords='axes fraction', color='black', fontsize=12)\n",
    "        plt.annotate(f'σ = Standard Deviation: {std_dev_area}', xy=(0.75, 0.8), xycoords='axes fraction', color='black', fontsize=12)\n",
    "        plt.annotate(f'P = 95th Percentile(red): {percentile}', xy=(0.75, 0.75), xycoords='axes fraction', color='black', fontsize=12)\n",
    "\n",
    "        # Place an asterisk precisely on the x-axis at the mean_area value\n",
    "        plt.annotate('|', xy=(mean_area, 0), xycoords='data', color='black', fontsize=10, ha='center', va='center')\n",
    "        plt.annotate('μ', xy=(mean_area, 0), xycoords='data', color='black', fontsize=12, ha='center', va='top')\n",
    "\n",
    "        # Add annotations for mean + standard deviation and mean - standard deviation on the x-axis below the axis\n",
    "        plt.annotate('μ+σ', xy=(mean_plus_std, 0), xycoords='data', color='black', fontsize=12, ha='center', va='top')\n",
    "        plt.annotate('μ-σ', xy=(mean_minus_std, 0), xycoords='data', color='black', fontsize=12, ha='center', va='top')\n",
    "        plt.annotate('|', xy=(mean_plus_std, 0), xycoords='data', color='black', fontsize=10, ha='center', va='center')\n",
    "        plt.annotate('|', xy=(mean_minus_std, 0), xycoords='data', color='black', fontsize=10, ha='center', va='center')\n",
    "\n",
    "        # Add annotations for mean + 2*standard deviation and mean - 2*standard deviation on the x-axis below the axis\n",
    "        plt.annotate('μ+2σ', xy=(mean_plus_2std, 0), xycoords='data', color='black', fontsize=12, ha='center', va='top')\n",
    "        plt.annotate('μ-2σ', xy=(mean_minus_2std, 0), xycoords='data', color='black', fontsize=12, ha='center', va='top')\n",
    "        plt.annotate('|', xy=(mean_plus_2std, 0), xycoords='data', color='black', fontsize=10, ha='center', va='center')\n",
    "        plt.annotate('|', xy=(mean_minus_2std, 0), xycoords='data', color='black', fontsize=10, ha='center', va='center')\n",
    "\n",
    "        plt.annotate('|', xy=(percentile, 0), xycoords='data', color='red', fontsize=15, ha='center', va='center')\n",
    "\n",
    "        # Save the plot to a file\n",
    "        image_filename_scatter = os.path.join(input_directory, f'{csv_file_name}_area_scatter_plot.png')\n",
    "        plt.savefig(image_filename_scatter, bbox_inches='tight', format='png')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        #area vs aspect ratio\n",
    "        df_inc=df_in.copy()\n",
    "        # Calculate the ratio of short side to long side (width/height)\n",
    "        df_inc['short_side'] = df_inc[['width', 'height']].min(axis=1)\n",
    "        df_inc['long_side'] = df_inc[['width', 'height']].max(axis=1)\n",
    "        df_inc['ratio'] = df_inc['short_side'] / df_inc['long_side']\n",
    "\n",
    "        # Create a scatter plot with ratio on the x-axis and area on the y-axis\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(df_inc['ratio'], df_inc['area'], s=10, c='violet', alpha=0.7)\n",
    "\n",
    "        # Add labels and title\n",
    "        plt.xlabel('Short Side / Long Side (Ratio)')\n",
    "        plt.ylabel('Area')\n",
    "        plt.title('Scatter Plot of Short Side/Long Side vs. Area')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.grid()\n",
    "        # Set the X-axis range to the minimum and maximum area values\n",
    "        plt.ylim(min(area_values), max(area_values))\n",
    "\n",
    "        # Save the figure with a filename\n",
    "        image_filename_aspect_ratio = os.path.join(input_directory, f'{csv_file_name}_Aspect_ratio_vs_area.png')\n",
    "        plt.savefig(image_filename_aspect_ratio, bbox_inches='tight', format='png')\n",
    "        plt.show()\n",
    "\n",
    "       \n",
    "\n",
    "    def area_analysis(df):\n",
    "        # Filter rows where 'area' is greater than 4000\n",
    "        rows_with_high_area = df[df['area'] > 4000]\n",
    "        statements_area = []\n",
    "        frames_unique_high_area = rows_with_high_area[(rows_with_high_area['classid'] != -1) & (rows_with_high_area['classid'] != 2)]\n",
    "        frames_unique_entries_area = frames_unique_high_area['frame'].nunique()\n",
    "\n",
    "        # Print the number of unique entries\n",
    "        print(\"Number of unique frames with area above 4000:\", frames_unique_entries_area)\n",
    "\n",
    "        # Get the unique combination of 'classid' and 'id' values for all individuals\n",
    "        unique_individuals_area = rows_with_high_area[['classid', 'id']].drop_duplicates()\n",
    "\n",
    "        unique_individuals_area = unique_individuals_area[(unique_individuals_area['classid'] != -1) & (unique_individuals_area['classid'] != 2)]\n",
    "\n",
    "        # Calculate the total number of unique individuals\n",
    "        total_individuals_area = len(unique_individuals_area)\n",
    "\n",
    "        # Print the total number of unique individuals\n",
    "        print(\"Total Number of Unique Individuals (Male and Female):\", total_individuals_area)\n",
    "\n",
    "        # Check if frames_unique_entries_area is greater than 0\n",
    "        if frames_unique_entries_area > 0:\n",
    "            # Create an empty DataFrame to store the results\n",
    "            df_area = unique_individuals_area.copy()\n",
    "\n",
    "            # Function to count frames where area > 4000 for an individual\n",
    "            def count_frames_above_4000(classid, individual_id):\n",
    "                filtered_df = df[(df['classid'] == classid) & (df['id'] == individual_id)]\n",
    "                frames_above_4000 = len(filtered_df[filtered_df['area'] > 4000])\n",
    "                return frames_above_4000\n",
    "\n",
    "            # Apply the function to each row of df_area and store the result in a new column\n",
    "            df_area['no of frames>4000'] = df_area.apply(lambda row: count_frames_above_4000(row['classid'], row['id']), axis=1)\n",
    "\n",
    "            # Create an empty list to store the statements\n",
    "            statements_area = []\n",
    "\n",
    "            # Function to count frames where area > 4000 for an individual and generate statements\n",
    "            def generate_statements(classid, individual_id):\n",
    "                filtered_df = df[(df['classid'] == classid) & (df['id'] == individual_id)]\n",
    "                frames_above_4000 = len(filtered_df[filtered_df['area'] > 4000])\n",
    "\n",
    "                # Generate the statement and append it to the list\n",
    "                statement = f\"ID {individual_id} (Class {classid}) has bounding boxes of area above 4000 in {frames_above_4000} number of frames.\"\n",
    "                statements_area.append(statement)\n",
    "\n",
    "            # Apply the function to each row of df_area\n",
    "            df_area.apply(lambda row: generate_statements(row['classid'], row['id']), axis=1)\n",
    "\n",
    "            # Print the generated statements\n",
    "            for statement in statements_area:\n",
    "                print(statement)\n",
    "        else:\n",
    "            print(\"No unique entries found above threshold.\")\n",
    "\n",
    "        return total_individuals_area,  unique_individuals_area, frames_unique_entries_area, total_individuals_area, statements_area\n",
    "\n",
    "    \n",
    "    # Function to plot graphs for individuals above 4000\n",
    "    def create_individual_plots(df, unique_individuals_area, csv_file_name):\n",
    "        if 50> total_individuals_area > 0:\n",
    "            # Create a single figure to contain all plots\n",
    "            fig, axes = plt.subplots(len(unique_individuals_area), 1, figsize=(20, 8 * len(unique_individuals_area)))\n",
    "\n",
    "            for i, (_, row) in enumerate(unique_individuals_area.iterrows()):\n",
    "                classid, individual_id = row['classid'], row['id']\n",
    "\n",
    "                # Select the current subplot\n",
    "                ax = axes[i]\n",
    "\n",
    "                # Clear the previous plot from the subplot\n",
    "                ax.clear()\n",
    "\n",
    "                filtered_df = df[(df['classid'] == classid) & (df['id'] == individual_id)]\n",
    "                grouped_df = filtered_df.groupby('frame')['area'].mean()\n",
    "\n",
    "                ax.set_title(f'Area vs. Frame for Class {classid}, Individual {individual_id}')\n",
    "                ax.set_xlabel('Frame')\n",
    "                ax.set_ylabel('Area')\n",
    "\n",
    "                # Plot the data points with a slight curve\n",
    "                x = grouped_df.index\n",
    "                y = grouped_df.values\n",
    "                ax.plot(x, y, color='green', linestyle='-', linewidth=1)  # Adjust the linewidth for a thicker line\n",
    "\n",
    "                # Set X axis ticks to be every 30 frames\n",
    "                ax.set_xticks(range(0, max(x) + 1, 200))\n",
    "\n",
    "                # Show gridlines\n",
    "                ax.grid(True)\n",
    "\n",
    "\n",
    "             # Save the figure containing all plots with the CSV file name as part of the filename\n",
    "\n",
    "            image_filename_area = os.path.join(input_directory, f'{csv_file_name}_individual with area above 4000.png')\n",
    "            plt.savefig(image_filename_area, bbox_inches='tight', format='png')\n",
    "\n",
    "            # Show the figure (optional, comment this line to save only)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def save_dataframe_to_csv(df, input_csv_file_path):\n",
    "        # Extract the directory path from the input CSV file's path\n",
    "        output_directory = os.path.dirname(input_csv_file_path)\n",
    "        df_in.sort_values(by='frame', inplace=True)\n",
    "\n",
    "        # Extract the file name without extension from the input CSV file's path\n",
    "        file_name_without_extension = os.path.splitext(os.path.basename(input_csv_file_path))[0]\n",
    "\n",
    "        # Define the CSV file path for saving\n",
    "        csv_file_path = os.path.join(output_directory, f'Analysed_{file_name_without_extension}.csv')\n",
    "\n",
    "        # Save the DataFrame to CSV without headers\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "        return csv_file_path\n",
    "\n",
    "    def text_save(\n",
    "        input_directory,\n",
    "        csv_file_name,\n",
    "        frames_with_classid_error,\n",
    "        frames_with_duplicates,\n",
    "        frames_unique_entries_area,\n",
    "        total_individuals_area,\n",
    "        unique_frames_count,\n",
    "        unique_individuals,\n",
    "        statements_area,\n",
    "        filtered_disappearance_statements,\n",
    "        sentences_iou,\n",
    "        row_with_iou_0,\n",
    "        box_classid_error,\n",
    "        duplicate_statements\n",
    "    ):\n",
    "        # Define the text file name with the desired format\n",
    "        text_file_name = os.path.join(input_directory, f'Analysed_{csv_file_name}.txt')\n",
    "\n",
    "        # Check if there are frames with classid errors, duplicates, or other conditions\n",
    "        if (\n",
    "            len(frames_with_classid_error) > 0\n",
    "            or len(frames_with_duplicates) > 0\n",
    "            or frames_unique_entries_area > 0\n",
    "            or total_individuals_area > 0\n",
    "            or len(filtered_disappearance_statements) > 0\n",
    "            or len(row_with_iou_0) > 0\n",
    "        ):\n",
    "            # Create a text file and write the frames with classid errors, duplicates, and error messages to it\n",
    "            with open(text_file_name, 'w') as file:\n",
    "                if len(frames_with_classid_error) > 0:\n",
    "                    file.write(\"Frames with classid errors:\\n\")\n",
    "                    file.write(','.join(map(str, frames_with_classid_error)) + '\\n')\n",
    "                    file.write(\"Total no of boxes with classid error: {}\\n\".format(box_classid_error))\n",
    "                    file.write(\"\\n\")  # Add a line gap\n",
    "\n",
    "                if len(frames_with_duplicates) > 0:\n",
    "                    file.write(\"Frames with duplicates:\\n\")\n",
    "                    file.write(','.join(map(str, frames_with_duplicates)) + '\\n')\n",
    "                    for statement in duplicate_statements:\n",
    "                        file.write(statement + '\\n')\n",
    "                    file.write(\"\\n\")  # Add a line gap\n",
    "\n",
    "                if frames_unique_entries_area > 0:\n",
    "                    file.write(f\"\\nOut of {unique_frames_count} frames, no of frames with bounding box area greater than 4000: {frames_unique_entries_area}\\n\")\n",
    "\n",
    "                if total_individuals_area > 0:\n",
    "                    file.write(f\"\\nOut of {len(unique_individuals)} individuals, no of individuals with bounding box area greater than 4000: {total_individuals_area}\\n\")\n",
    "                    for statement in statements_area:\n",
    "                        file.write(statement + '\\n')\n",
    "                    file.write(\"\\n\")  # Add a line gap\n",
    "\n",
    "                if len(filtered_disappearance_statements) > 0:\n",
    "                    file.write(\"\\nDisappearance Statements:\\n\")\n",
    "                    for statement in filtered_disappearance_statements:\n",
    "                        file.write(statement + '\\n')\n",
    "                    file.write(\"\\n\")  # Add a line gap\n",
    "\n",
    "                if len(row_with_iou_0) > 0:\n",
    "                    file.write(\"Intersection over union = 0:\\n\")\n",
    "                    for sentence_iou in sentences_iou:\n",
    "                        file.write(sentence_iou + '\\n')\n",
    "\n",
    "        return text_file_name\n",
    "\n",
    "     # Call the process_csv function\n",
    "    df_in, unique_frames_count, total_individuals, unique_individuals = process_csv(csv_file_path)\n",
    "\n",
    "    # Call the class_id_error function\n",
    "   \n",
    "    df_in, frames_with_classid_error, box_classid_error = class_error(df_in)\n",
    "    df_in, frames_with_duplicates, duplicate_statements = duplicates(df_in)\n",
    "    df_in, sentences_iou, row_with_iou_0 = iou(df_in) \n",
    "    total_individuals_area,  unique_individuals_area, frames_unique_entries_area, total_individuals_area, statements_area = area_analysis(df_in)\n",
    "    filtered_disappearance_statements = disappearing_boxes(df_in, frames_with_classid_error, frames_with_duplicates)\n",
    "    \n",
    "    # Call the plot1 function\n",
    "    csv_file_name = os.path.splitext(os.path.basename(csv_file_path))[0]\n",
    "    input_directory = os.path.dirname(csv_file_path)\n",
    "    plot1(df_in)\n",
    "    create_individual_plots(df_in, unique_individuals_area, csv_file_name)\n",
    "    csv_file_path = save_dataframe_to_csv(df_in, csv_file_path)\n",
    "    txt_file_path = text_save(\n",
    "        input_directory,\n",
    "        csv_file_name,\n",
    "        frames_with_classid_error,\n",
    "        frames_with_duplicates,\n",
    "        frames_unique_entries_area,\n",
    "        total_individuals_area,\n",
    "        unique_frames_count,\n",
    "        unique_individuals,\n",
    "        statements_area,\n",
    "        filtered_disappearance_statements,\n",
    "        sentences_iou,\n",
    "        row_with_iou_0,\n",
    "        box_classid_error,\n",
    "        duplicate_statements\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc02e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
