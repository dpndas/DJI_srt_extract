{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d78d6fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ae009",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def analyze_csv_file(csv_file_path):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import cv2\n",
    "    import os\n",
    "    import math \n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "    from ipywidgets import Dropdown, interactive, widgets, Output\n",
    "    from scipy.interpolate import make_interp_spline\n",
    "    \n",
    "    \n",
    "    # Define the column headers\n",
    "    headers = ['frame', 'classid','id', 'x1', 'y1', 'width', 'height','a','b','c','d']\n",
    "\n",
    "    # Read the CSV file into a DataFrame and assign the headers\n",
    "    df_in = pd.read_csv(csv_file_path, header=None, names=headers)\n",
    "    \n",
    "    # Get the directory path of the input CSV file\n",
    "    input_directory = os.path.dirname(csv_file_path)\n",
    "    \n",
    "\n",
    "    df_in['area'] = df_in['width'] * df_in['height']\n",
    "\n",
    "    # Find the number of unique frames in the 'frames' column of df_in\n",
    "    unique_frames_count = df_in['frame'].nunique()\n",
    "    unique_individuals = df_in[['classid', 'id']].drop_duplicates()\n",
    "   \n",
    "    # Remove entries with classid 2 or -1 from unique_individuals DataFrame\n",
    "    unique_individuals = unique_individuals[(unique_individuals['classid'] != 2) & (unique_individuals['classid'] != -1)]\n",
    "    # Calculate the total number of unique individuals\n",
    "    total_individuals = len(unique_individuals)\n",
    "    # Filter the DataFrame to exclude rows where 'classid' is 2\n",
    "    df_area_filtered = df_in[df_in['classid'] != 2]\n",
    "    csv_file_name = os.path.splitext(os.path.basename(csv_file_path))[0]\n",
    "    # Calculate the frequency of each area value\n",
    "    area_counts = df_area_filtered['area'].value_counts().sort_index()\n",
    "\n",
    "    \n",
    "    #PLOT 1\n",
    "    # Extract area values and their frequencies\n",
    "    area_values = area_counts.index\n",
    "    frequencies = area_counts.values\n",
    "    # Calculate the mean area\n",
    "    mean_area = df_area_filtered['area'].mean()\n",
    "\n",
    "    # Calculate the standard deviation of the area values\n",
    "    std_dev_area = round(df_area_filtered['area'].std(), 3)\n",
    "\n",
    "\n",
    "    # Calculate the values for mean + standard deviation and mean - standard deviation\n",
    "    mean_plus_std = mean_area + std_dev_area\n",
    "    mean_minus_std = mean_area - std_dev_area\n",
    "\n",
    "    # Calculate the values for mean + standard deviation and mean - standard deviation\n",
    "    mean_plus_2std = mean_area + 2*std_dev_area\n",
    "    mean_minus_2std = mean_area - 2*std_dev_area\n",
    "\n",
    "\n",
    "    #Finding the 95th percentile\n",
    "      # Import the math module\n",
    "\n",
    "    def calculate_percentile(df, column, percentile):\n",
    "        df = df.sort_values(by=column)\n",
    "        index = (len(df) - 1) * percentile\n",
    "        floor_index = math.floor(index)\n",
    "        ceil_index = math.ceil(index)\n",
    "        if floor_index == ceil_index:\n",
    "            return df.iloc[int(index)][column]\n",
    "        else:\n",
    "            floor_value = df.iloc[floor_index][column] \n",
    "            ceil_value = df.iloc[ceil_index][column]\n",
    "            return floor_value + (ceil_value - floor_value) * (index - floor_index)\n",
    "\n",
    "    percentile = (calculate_percentile(df_in, 'area', 0.95))\n",
    "\n",
    "    # Create a scatter plot with green color\n",
    "    plt.figure(figsize=(15, 11))  # Reduced figure size\n",
    "    plt.scatter(area_values, frequencies, color=\"green\", marker='o', s=12)\n",
    "    plt.xlabel('Area')\n",
    "    plt.ylabel('No of bounding boxes')\n",
    "    plt.title('Scatter Plot of Bounding Box Areas')\n",
    "    plt.grid()\n",
    "\n",
    "    # Set the X-axis range to the minimum and maximum area values\n",
    "    plt.xlim(min(area_values), max(area_values))\n",
    "\n",
    "\n",
    "    # Annotate the plot with the lowest and highest area values\n",
    "    plt.annotate(f'Min Area: {min(area_values)}', xy=(0.75, 0.95), xycoords='axes fraction', color='black', fontsize=12)\n",
    "    plt.annotate(f'Max Area: {max(area_values)}', xy=(0.75, 0.9), xycoords='axes fraction', color='black', fontsize=12)\n",
    "    plt.annotate(f'μ = Mean Area: {mean_area:.2f}', xy=(0.75, 0.85), xycoords='axes fraction', color='black', fontsize=12)\n",
    "    plt.annotate(f'σ = Standered deviation: {std_dev_area}', xy=(0.75, 0.8), xycoords='axes fraction', color='black', fontsize=12)\n",
    "    plt.annotate(f'P = 95th Percentile(red): {percentile}', xy=(0.75, 0.75), xycoords='axes fraction', color='black', fontsize=12)\n",
    "\n",
    "    # Place an asterisk precisely on the x-axis at the mean_area value\n",
    "    plt.annotate('|', xy=(mean_area, 0), xycoords='data', color='black', fontsize=10, ha='center', va='center')\n",
    "    plt.annotate('μ', xy=(mean_area, 0), xycoords='data', color='black', fontsize=12, ha='center', va='top')\n",
    "\n",
    "    # Add annotations for mean + standard deviation and mean - standard deviation on the x-axis below the axis\n",
    "    plt.annotate('μ+σ', xy=(mean_plus_std, 0), xycoords='data', color='black', fontsize=12, ha='center', va='top')\n",
    "    plt.annotate('μ-σ', xy=(mean_minus_std, 0), xycoords='data', color='black', fontsize=12, ha='center', va='top')\n",
    "    plt.annotate('|', xy=(mean_plus_std, 0), xycoords='data', color='black', fontsize=10, ha='center', va='center')\n",
    "    plt.annotate('|', xy=(mean_minus_std, 0), xycoords='data', color='black', fontsize=10, ha='center', va='center')\n",
    "\n",
    "    # Add annotations for mean + standard deviation and mean - standard deviation on the x-axis below the axis\n",
    "    plt.annotate('μ+2σ', xy=(mean_plus_2std, 0), xycoords='data', color='black', fontsize=12, ha='center', va='top')\n",
    "    plt.annotate('μ-2σ', xy=(mean_minus_2std, 0), xycoords='data', color='black', fontsize=12, ha='center', va='top')\n",
    "    plt.annotate('|', xy=(mean_plus_2std, 0), xycoords='data', color='black', fontsize=10, ha='center', va='center')\n",
    "    plt.annotate('|', xy=(mean_minus_2std, 0), xycoords='data', color='black', fontsize=10, ha='center', va='center')\n",
    "\n",
    "\n",
    "    plt.annotate('|', xy=(percentile, 0), xycoords='data', color='red', fontsize=15, ha='center', va='center')\n",
    "\n",
    "\n",
    "    # Save the figure with a filename\n",
    "\n",
    "    image_filename_scatter = os.path.join(input_directory, f'{csv_file_name}_area_scatter_plot.png')\n",
    "    plt.savefig(image_filename_scatter, bbox_inches='tight', format='png')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    #PLOT 2\n",
    "    df_inc=df_in.copy()\n",
    "    # Calculate the ratio of short side to long side (width/height)\n",
    "    df_inc['short_side'] = df_inc[['width', 'height']].min(axis=1)\n",
    "    df_inc['long_side'] = df_inc[['width', 'height']].max(axis=1)\n",
    "    df_inc['ratio'] = df_inc['short_side'] / df_inc['long_side']\n",
    "\n",
    "    # Create a scatter plot with ratio on the x-axis and area on the y-axis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df_inc['ratio'], df_inc['area'], s=10, c='violet', alpha=0.7)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Short Side / Long Side (Ratio)')\n",
    "    plt.ylabel('Area')\n",
    "    plt.title('Scatter Plot of Short Side/Long Side vs. Area')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid()\n",
    "    # Set the X-axis range to the minimum and maximum area values\n",
    "    plt.ylim(min(area_values), max(area_values))\n",
    "\n",
    "    # Save the figure with a filename\n",
    "    image_filename_aspect_ratio = os.path.join(input_directory, f'{csv_file_name}_Aspect_ratio_vs_area.png')\n",
    "    plt.savefig(image_filename_aspect_ratio, bbox_inches='tight', format='png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #CLASS ID ERROR\n",
    "    # Create a new column 'classid_error' and initialize it with 0\n",
    "    df_in['classid_error'] = 0\n",
    "\n",
    "    # Function to update 'classid_error' column based on 'classid' column\n",
    "    def update_classid_error(row):\n",
    "        if row['classid'] == -1:\n",
    "            return 1\n",
    "        else:\n",
    "            return row['classid_error']\n",
    "\n",
    "    # Apply the update_classid_error function to each row\n",
    "    df_in['classid_error'] = df_in.apply(update_classid_error, axis=1)\n",
    "\n",
    "    df_in['classid_error_frame'] = 0\n",
    "\n",
    "    # Find frames with 'classid_error' entry of 1\n",
    "    frames_with_classid_error = df_in[df_in['classid_error'] == 1]['frame'].unique()\n",
    "\n",
    "    # Update 'classid_error_frame' column for the identified frames\n",
    "    df_in.loc[df_in['frame'].isin(frames_with_classid_error), 'classid_error_frame'] = 1\n",
    "\n",
    "    # Print frames with duplicates\n",
    "    print(\"Frames with classid errors:\", frames_with_classid_error)\n",
    "    \n",
    "    \n",
    "    #DUPLICATES ERROR\n",
    "    # Create a new column 'duplicates' indicating if a row is a duplicate\n",
    "    df_in['duplicates'] = df_in.groupby(['frame', 'classid'])['id'].transform(lambda x: x.duplicated(keep=False).astype(int))\n",
    "\n",
    "    # Find unique frames with duplicates\n",
    "    frames_with_duplicates = df_in.loc[df_in['duplicates'] == 1, 'frame'].unique()\n",
    "\n",
    "    # Create 'duplicate_frame' column and set values based on 'frame' and 'frames_with_duplicates'\n",
    "    df_in['duplicate_frame'] = df_in['frame'].apply(lambda x: 1 if x in frames_with_duplicates else 0)\n",
    "\n",
    "    # Print frames with duplicates\n",
    "    print(\"Frames with Duplicates:\", frames_with_duplicates)\n",
    "\n",
    "   \n",
    "    \n",
    "    #DISAPPEARING - REAPPEARING ERROR\n",
    "    # Sort the DataFrame by 'id' and 'frame' in ascending order\n",
    "    df_in.sort_values(by=['id', 'frame'], inplace=True)\n",
    "\n",
    "    # Create a dictionary to store the last frame for each individual\n",
    "    last_frame_dict = {}\n",
    "    disappearance_statements = []  # Initialize a list to store disappearance statements\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in df_in.iterrows():\n",
    "        classid = row['classid']\n",
    "        individual_id = row['id']\n",
    "        frame = row['frame']\n",
    "\n",
    "        # Check if the individual was present in the previous frame\n",
    "        if (classid, individual_id) in last_frame_dict:\n",
    "            last_frame = last_frame_dict[(classid, individual_id)]\n",
    "\n",
    "            if frame != last_frame + 1:\n",
    "                statement = f\"ID {individual_id} (Class {classid}) disappeared in frame {last_frame} and reappeared in frame {frame}\"\n",
    "                disappearance_statements.append(statement)  # Collect the statements\n",
    "\n",
    "        # Update the last frame for the individual\n",
    "        last_frame_dict[(classid, individual_id)] = frame\n",
    "\n",
    "    # Create a new list without entries containing 'Class -1' and not having one less of the numbers stored in 'frames_with_classid_error'\n",
    "    filtered_disappearance_statements = [\n",
    "        statement for statement in disappearance_statements \n",
    "        if 'Class -1' not in statement \n",
    "        and all(f\"frame {frame - 1}\" not in statement for frame in frames_with_classid_error)\n",
    "        and all(f\"frame {frame}\" not in statement for frame in frames_with_duplicates)\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Print the filtered list\n",
    "    for statement in filtered_disappearance_statements:\n",
    "        print(statement)\n",
    "        \n",
    "        \n",
    "    #AREA ABOVE 4000   \n",
    "    # Filter rows where 'area' is greater than 4000\n",
    "    rows_with_high_area = df_in[df_in['area'] > 4000]\n",
    "\n",
    "    frames_unique_high_area = rows_with_high_area[(rows_with_high_area['classid'] != -1) & (rows_with_high_area['classid'] != 2)]\n",
    "    frames_unique_entries_area = frames_unique_high_area['frame'].nunique()\n",
    "\n",
    "    # Print the number of unique entries\n",
    "    print(\"Number of unique frames with area above 4000:\", frames_unique_entries_area)\n",
    "\n",
    "\n",
    "    # Get the unique combination of 'classid' and 'id' values for all individuals\n",
    "    unique_individuals_area = rows_with_high_area[['classid', 'id']].drop_duplicates()\n",
    "\n",
    "    unique_individuals_area = unique_individuals_area[(unique_individuals_area['classid'] != -1) & (unique_individuals_area['classid'] != 2)]\n",
    "\n",
    "    # Calculate the total number of unique individuals\n",
    "    total_individuals_area = len(unique_individuals_area)\n",
    "\n",
    "    # Print the total number of unique individuals\n",
    "    print(\"Total Number of Unique Individuals (Male and Female):\", total_individuals_area)\n",
    "    # Check if frames_unique_entries_area is greater than 0\n",
    "    if frames_unique_entries_area > 0:\n",
    "        # Create an empty DataFrame to store the results\n",
    "        df_area = unique_individuals_area.copy()\n",
    "\n",
    "        # Function to count frames where area > 4000 for an individual\n",
    "        def count_frames_above_4000(classid, individual_id):\n",
    "            filtered_df = df_in[(df_in['classid'] == classid) & (df_in['id'] == individual_id)]\n",
    "            frames_above_4000 = len(filtered_df[filtered_df['area'] > 4000])\n",
    "            return frames_above_4000\n",
    "\n",
    "        # Apply the function to each row of df_area and store the result in a new column\n",
    "        df_area['no of frames>4000'] = df_area.apply(lambda row: count_frames_above_4000(row['classid'], row['id']), axis=1)\n",
    "\n",
    "        # Create an empty list to store the statements\n",
    "        statements_area = []\n",
    "\n",
    "        # Function to count frames where area > 4000 for an individual and generate statements\n",
    "        def generate_statements(classid, individual_id):\n",
    "            filtered_df = df_in[(df_in['classid'] == classid) & (df_in['id'] == individual_id)]\n",
    "            frames_above_4000 = len(filtered_df[filtered_df['area'] > 4000])\n",
    "\n",
    "            # Generate the statement and append it to the list\n",
    "            statement = f\"ID {individual_id} (Class {classid}) has bounding boxes of area above 4000 in {frames_above_4000} number of frames.\"\n",
    "            statements_area.append(statement)\n",
    "\n",
    "        # Apply the function to each row of df_area\n",
    "        df_area.apply(lambda row: generate_statements(row['classid'], row['id']), axis=1)\n",
    "\n",
    "        # Print the generated statements\n",
    "        for statement in statements_area:\n",
    "            print(statement)\n",
    "    else:\n",
    "        print(\"No unique entries found in frames_unique_entries_area.\")\n",
    "    # Extract the CSV file name without the extension\n",
    "    csv_file_name = os.path.splitext(os.path.basename(csv_file_path))[0]\n",
    "    \n",
    "    \n",
    "    #PLOT 3\n",
    "\n",
    "\n",
    "    # Function to plot graphs for each unique combination\n",
    "    def create_individual_plots(df, unique_individuals_area, csv_file_name):\n",
    "        if 50> total_individuals_area > 0:\n",
    "            # Create a single figure to contain all plots\n",
    "            fig, axes = plt.subplots(len(unique_individuals_area), 1, figsize=(20, 8 * len(unique_individuals_area)))\n",
    "\n",
    "            for i, (_, row) in enumerate(unique_individuals_area.iterrows()):\n",
    "                classid, individual_id = row['classid'], row['id']\n",
    "\n",
    "                # Select the current subplot\n",
    "                ax = axes[i]\n",
    "\n",
    "                # Clear the previous plot from the subplot\n",
    "                ax.clear()\n",
    "\n",
    "                filtered_df = df[(df['classid'] == classid) & (df['id'] == individual_id)]\n",
    "                grouped_df = filtered_df.groupby('frame')['area'].mean()\n",
    "\n",
    "                ax.set_title(f'Area vs. Frame for Class {classid}, Individual {individual_id}')\n",
    "                ax.set_xlabel('Frame')\n",
    "                ax.set_ylabel('Area')\n",
    "\n",
    "                # Plot the data points with a slight curve\n",
    "                x = grouped_df.index\n",
    "                y = grouped_df.values\n",
    "                ax.plot(x, y, color='green', linestyle='-', linewidth=1)  # Adjust the linewidth for a thicker line\n",
    "\n",
    "                # Set X axis ticks to be every 30 frames\n",
    "                ax.set_xticks(range(0, max(x) + 1, 200))\n",
    "\n",
    "                # Show gridlines\n",
    "                ax.grid(True)\n",
    "\n",
    "            # Save the figure containing all plots with the CSV file name as part of the filename\n",
    "\n",
    "            image_filename_aspect_ratio = os.path.join(input_directory, f'{csv_file_name}_individual with area above 4000.png')\n",
    "            plt.savefig(image_filename_aspect_ratio, bbox_inches='tight', format='png')\n",
    "\n",
    "            # Show the figure (optional, comment this line to save only)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    create_individual_plots(df_in, unique_individuals_area, csv_file_name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #INTERSECTION OVER UNION\n",
    "\n",
    "    # Sort the DataFrame by 'classid', 'id', and 'frame' in ascending order\n",
    "    df_in.sort_values(by=['classid', 'id', 'frame'], inplace=True)\n",
    "\n",
    "    # Create a new column to store the IoU values\n",
    "    df_in['iou'] = 0.0  # Initialize with zeros\n",
    "\n",
    "    # Create a dictionary to store the last bounding box coordinates for each individual within each class\n",
    "    last_bbox_dict = {}\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in df_in.iterrows():\n",
    "        classid = row['classid']\n",
    "        individual_id = row['id']\n",
    "        frame = row['frame']\n",
    "        x1 = row['x1']\n",
    "        y1 = row['y1']\n",
    "        width = row['width']\n",
    "        height = row['height']\n",
    "\n",
    "        # Check if the individual within a class was present in the previous frame\n",
    "        if (classid, individual_id) in last_bbox_dict:\n",
    "            last_x1, last_y1, last_width, last_height = last_bbox_dict[(classid, individual_id)]\n",
    "\n",
    "            # Calculate the coordinates of the current bounding box\n",
    "            x2 = x1 + width\n",
    "            y2 = y1 + height\n",
    "\n",
    "            # Calculate the coordinates of the last known bounding box\n",
    "            last_x2 = last_x1 + last_width\n",
    "            last_y2 = last_y1 + last_height\n",
    "\n",
    "            # Calculate the intersection coordinates\n",
    "            intersection_x1 = max(x1, last_x1)\n",
    "            intersection_y1 = max(y1, last_y1)\n",
    "            intersection_x2 = min(x2, last_x2)\n",
    "            intersection_y2 = min(y2, last_y2)\n",
    "\n",
    "            # Calculate the areas of the current and last bounding boxes\n",
    "            area_current = (x2 - x1) * (y2 - y1)\n",
    "            area_last = (last_x2 - last_x1) * (last_y2 - last_y1)\n",
    "\n",
    "            # Calculate the area of intersection\n",
    "            area_intersection = max(0, intersection_x2 - intersection_x1) * max(0, intersection_y2 - intersection_y1)\n",
    "\n",
    "            # Calculate the IoU\n",
    "            iou = area_intersection / (area_current + area_last - area_intersection)\n",
    "\n",
    "            # Update the DataFrame with the calculated IoU\n",
    "            df_in.at[index, 'iou'] = iou\n",
    "\n",
    "        # Update the last bounding box coordinates for the individual within the class\n",
    "        last_bbox_dict[(classid, individual_id)] = (x1, y1, width, height)\n",
    "\n",
    "    #Finding boxes with IOU=0    \n",
    "    row_with_iou_0 = df_in[(df_in['iou'] == 0) & (df_in['frame'] != df_in.groupby(['classid', 'id'])['frame'].transform('min')) & (df_in['classid'] != -1)]\n",
    "\n",
    "    len(row_with_iou_0)\n",
    "\n",
    "    # Initialize an empty list to store sentences\n",
    "    sentences_iou = []\n",
    "\n",
    "    # Iterate through the rows of row_with_iou_0 DataFrame\n",
    "    for index, row in row_with_iou_0.iterrows():\n",
    "        classid = row['classid']\n",
    "        id_value = row['id']\n",
    "        frame_start = row['frame']\n",
    "        frame_end = frame_start - 1  # Subtract 1 from frame_start\n",
    "\n",
    "        # Create the sentence in the desired format\n",
    "        sentence_iou = f'ID {id_value} (Class {classid}) has IOU value 0 between the frames {frame_end} and {frame_start}'\n",
    "\n",
    "\n",
    "        # Append the sentence to the list\n",
    "        sentences_iou.append(sentence_iou)\n",
    "\n",
    "    # Print the sentences or save them as needed\n",
    "    for sentence_iou in sentences_iou:\n",
    "        print(sentence_iou)\n",
    "    df_in.sort_values(by='frame', inplace=True)\n",
    "    \n",
    "    #SAVING THE CSV FILE \n",
    "    file_name_without_extension = os.path.splitext(os.path.basename(csv_file_path))[0]\n",
    "    csv_file_path = os.path.join(input_directory, f'Analysed_{file_name_without_extension}.csv')\n",
    "\n",
    "    # Save the edited DataFrame to CSV without headers in the same directory\n",
    "    df_in.to_csv(csv_file_path, index=False, header=False)\n",
    "    \n",
    "    # Define the text file name with the desired format\n",
    "    text_file_name = os.path.join(input_directory, f'Analysed_{file_name_without_extension}.txt')\n",
    "    \n",
    "    \n",
    "    #CREATING THE TEXT FILE\n",
    "    # Check if there are frames with classid errors, duplicates, or distance greater than 60\n",
    "    if len(frames_with_classid_error) > 0 or len(frames_with_duplicates) > 0 or frames_unique_entries_area > 0  or total_individuals_area > 0 or len(filtered_disappearance_statements) > 0 or len(row_with_iou_0) > 0:\n",
    "        # Create a text file and write the frames with classid errors, duplicates, and error messages to it\n",
    "        with open(text_file_name, 'w') as file:\n",
    "            if len(frames_with_classid_error) > 0:\n",
    "                file.write(\"Frames with classid errors:\\n\")\n",
    "                for i, frame in enumerate(frames_with_classid_error):\n",
    "                    file.write(str(frame))\n",
    "                    if i < len(frames_with_classid_error) - 1:\n",
    "                        file.write(\",\")\n",
    "\n",
    "                file.write(\"\\n\")  # Add a line gap\n",
    "\n",
    "            if len(frames_with_duplicates) > 0:\n",
    "                file.write(\"\\n\")  # Add a line gap\n",
    "                file.write(\"Frames with duplicates:\\n\")\n",
    "                for i, frame in enumerate(frames_with_duplicates):\n",
    "                    file.write(str(frame))\n",
    "                    if i < len(frames_with_duplicates) - 1:\n",
    "                        file.write(\",\")\n",
    "\n",
    "                file.write(\"\\n\")  # Add a line gap\n",
    "\n",
    "            if frames_unique_entries_area > 0:\n",
    "                file.write(f\"\\nOut of {unique_frames_count} frames, no of frames with bounding box area greater than 4000: {frames_unique_entries_area}\\n\")\n",
    "\n",
    "            if total_individuals_area > 0:\n",
    "                file.write(f\"\\nOut of {len(unique_individuals)} individuals, no of individuals with bounding box area greater than 4000: {total_individuals_area}\\n\")\n",
    "                for statement in statements_area:\n",
    "                    file.write(statement + '\\n')\n",
    "\n",
    "                file.write(\"\\n\")  # Add a line gap\n",
    "\n",
    "            if len(filtered_disappearance_statements) > 0:\n",
    "                file.write(\"\\nDisappearance Statements:\\n\")\n",
    "                for statement in filtered_disappearance_statements:\n",
    "                    file.write(statement + '\\n')\n",
    "\n",
    "                file.write(\"\\n\")  # Add a line gap\n",
    "\n",
    "            if len(row_with_iou_0) > 0:        \n",
    "                file.write(\"Intersection over union = 0:\\n\")\n",
    "                for sentence_iou in sentences_iou:\n",
    "                    file.write(sentence_iou + '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc02e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
