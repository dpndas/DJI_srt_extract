{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "038f06ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the session location: D:/MELA/Test Dataset SRT/20230308/SE_Lek1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:204: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_day['File path'] = df_day['File path'].str.replace('\\\\', '/')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:244: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['start_timestamp'] = df_p['start_timestamp'].str.replace(',', '')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['end_timestamp'] = df_p['end_timestamp'].str.replace(',', '')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:248: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['start_timestamp'] = pd.to_datetime(df_p['start_timestamp'], format='%H:%M:%S%f')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:249: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['end_timestamp'] = pd.to_datetime(df_p['end_timestamp'], format='%H:%M:%S%f')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:252: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['previous_end_timestamp'] = df_p['end_timestamp'].shift(1)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:255: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['end_start_diff'] = (df_p['previous_end_timestamp'] - df_p['start_timestamp']).dt.total_seconds().abs()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:244: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['start_timestamp'] = df_p['start_timestamp'].str.replace(',', '')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['end_timestamp'] = df_p['end_timestamp'].str.replace(',', '')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:248: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['start_timestamp'] = pd.to_datetime(df_p['start_timestamp'], format='%H:%M:%S%f')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:249: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['end_timestamp'] = pd.to_datetime(df_p['end_timestamp'], format='%H:%M:%S%f')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:252: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['previous_end_timestamp'] = df_p['end_timestamp'].shift(1)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:255: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['end_start_diff'] = (df_p['previous_end_timestamp'] - df_p['start_timestamp']).dt.total_seconds().abs()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:244: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['start_timestamp'] = df_p['start_timestamp'].str.replace(',', '')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['end_timestamp'] = df_p['end_timestamp'].str.replace(',', '')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:248: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['start_timestamp'] = pd.to_datetime(df_p['start_timestamp'], format='%H:%M:%S%f')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:249: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['end_timestamp'] = pd.to_datetime(df_p['end_timestamp'], format='%H:%M:%S%f')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:252: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['previous_end_timestamp'] = df_p['end_timestamp'].shift(1)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:255: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p['end_start_diff'] = (df_p['previous_end_timestamp'] - df_p['start_timestamp']).dt.total_seconds().abs()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:520: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_day['Global start time'].iloc[1:] = pd.to_datetime(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:521: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_day['Global end time'].iloc[1:] = pd.to_datetime(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:555: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_day['Global start time'].iloc[1:] = '0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16004\\2045442615.py:558: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_day['Global end time'].iloc[1:] = '0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:36:37.062824\n",
      "18:40:50.428953\n",
      "Corresponding Frame for first_video_p1: 722\n",
      "Corresponding Frame for first_video_p2: 226\n",
      "Corresponding Frame for first_video_p3: 1\n",
      "Corresponding Frame for last_video_p1: 5722\n",
      "Corresponding Frame for last_video_p2: 5689\n",
      "Corresponding Frame for last_video_p3: 2362\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Author : Dipin\n",
    "#Function create csv after analysing a drone session\n",
    "\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from geopy import distance\n",
    "import datetime\n",
    "from datetime import datetime, date\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "\n",
    "    # Ask the user for the session location\n",
    "    session_location = input(\"Enter the session location: \")\n",
    "\n",
    "    # Use glob to get a sorted list of folders\n",
    "    folders = sorted(glob.glob(session_location + '/*'))\n",
    "\n",
    "    df_day, df_plot, df_dict = dataframe_creation(folders)\n",
    "    \n",
    "    df_day = rearrange_columns(df_day)\n",
    "    \n",
    "    df_day, df_p1, df_p2, df_p3  = finding_missing_data(df_day)\n",
    "    \n",
    "    first_drone_P1, first_drone_P2, first_drone_P3, second_drone_P1, second_drone_P2, second_drone_P3 = drone_number(df_p1,\n",
    "                                                                                                                     df_p2,\n",
    "                                                                                                                     df_p3)\n",
    "    \n",
    "    df_day = sortieid(df_day,\n",
    "                      first_drone_P1,\n",
    "                      first_drone_P2,\n",
    "                      first_drone_P3,\n",
    "                      second_drone_P1,\n",
    "                      second_drone_P2,\n",
    "                      second_drone_P3)\n",
    "    \n",
    "    df_day, common_start_time, common_end_time = start_end_time(df_day, df_p1, df_p2, df_p3)\n",
    "    \n",
    "    first_video_p1, first_video_p2, first_video_p3, last_video_p1, last_video_p2, last_video_p3, fvp1, fvp2, fvp3, lvp1, lvp2, lvp3 = start_end_file(df_day,\n",
    "                                                                                                                                                     df_p1,\n",
    "                                                                                                                                                     df_p2,\n",
    "                                                                                                                                                     df_p3, \n",
    "                                                                                                                                                     common_start_time,\n",
    "                                                                                                                                                     common_end_time)\n",
    "    \n",
    "    df_day = start_end_frame(first_video_p1, \n",
    "                    first_video_p2,\n",
    "                    first_video_p3,\n",
    "                    last_video_p1,\n",
    "                    last_video_p2,\n",
    "                    last_video_p3,\n",
    "                    df_dict,\n",
    "                    common_start_time,\n",
    "                    common_end_time,\n",
    "                    df_p1,\n",
    "                    df_p2,\n",
    "                    df_p3,\n",
    "                    df_day,\n",
    "                    fvp1, fvp2, fvp3,\n",
    "                    lvp1, lvp2, lvp3\n",
    "                   )\n",
    "    \n",
    "    df_day = check_frame_drop(df_day)\n",
    "    \n",
    "    df_day,name = save_csv(df_day)\n",
    "    \n",
    "    save_txt(df_day, name)\n",
    "    \n",
    "    plot(df_plot)\n",
    "    \n",
    "  \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def extract_data_from_srt(file_path):\n",
    "    \"\"\"\n",
    "    Extracts data from a SubRip subtitle file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the subtitle file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the extracted data.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    # Use regular expressions to extract the frame number, timestamp, latitude, longitude, and altitude from each frame\n",
    "    frames = re.findall(r'(\\d+)\\n.*?(\\d{2}:\\d{2}:\\d{2},\\d{3},\\d{3}).*?\\[latitude:\\s*([-+]?\\d+\\.\\d+)\\]\\s*\\[longitude:\\s*([-+]?\\d+\\.\\d+)\\]\\s*\\[altitude:\\s*([-+]?\\d+\\.\\d+)\\]', content, re.DOTALL)\n",
    "    frame_times = re.findall(r'\\d{2}:\\d{2}:\\d{2},\\d{3} --> (\\d{2}:\\d{2}:\\d{2},\\d{3})', content)\n",
    "    \n",
    "    # Convert the extracted data into a list of dictionaries, where each dictionary represents one frame\n",
    "    results = [{'frame': int(frame), 'timestamp': str(timestamp), 'latitude': float(latitude), 'longitude': float(longitude), 'altitude': float(altitude), 'frame_time': frame_time} for (frame, timestamp, latitude, longitude, altitude), frame_time in zip(frames, frame_times)]\n",
    "   \n",
    "    # Convert the list of dictionaries into a pandas DataFrame and return it\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "def geodist(coord1, coord2_lat, coord2_long):\n",
    "    \"\"\"\n",
    "    Computes the geodesic distance between two geographic coordinates.\n",
    "\n",
    "    Args:\n",
    "        coord1 (tuple): A tuple representing the first coordinate, in the format (latitude, longitude).\n",
    "        coord2_lat (float): The latitude of the second coordinate.\n",
    "        coord2_long (float): The longitude of the second coordinate.\n",
    "\n",
    "    Returns:\n",
    "        float: The geodesic distance between the two coordinates, in metres.\n",
    "    \"\"\"\n",
    "    return distance.distance(coord1, (coord2_lat, coord2_long)).m\n",
    "\n",
    "\n",
    "def dataframe_creation(folders):\n",
    "    \"\"\"\n",
    "    Takes data drom the srt files and convert them to a data frame\n",
    "    \n",
    "    Args:\n",
    "        folders: Location of the files\n",
    "    \n",
    "    Return:\n",
    "        df_day: data frame creted for the whole session\n",
    "        df_plot: data frame to draw the graph at the end\n",
    "        df_dict: dictionary that contain data frame of every single srt file\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create empty lists to store dataframes and results\n",
    "    df_list = []\n",
    "    dist_max = []\n",
    "    drift_status = []\n",
    "    height_status = []\n",
    "    df_dict = {}\n",
    "    drift_thresh=5\n",
    "    height_thresh=7\n",
    "    \n",
    "    for folder in folders:\n",
    "        files = sorted(glob.glob(folder + '/*.SRT'))\n",
    "        \n",
    "        for file in files:\n",
    "            df_rec = extract_data_from_srt(file)\n",
    "            \n",
    "            # Working on altitude to find relay\n",
    "            df_rec['normal_altitude'] = 80.0\n",
    "            df_rec['height_difference'] = df_rec['altitude'] - df_rec['normal_altitude']\n",
    "            \n",
    "            if df_rec['height_difference'].max() > height_thresh:\n",
    "                height_status.append(1)\n",
    "            else:\n",
    "                height_status.append(0)\n",
    "            \n",
    "            # Working on drift\n",
    "            coord1 = (df_rec['latitude'].mean(), df_rec['longitude'].mean())\n",
    "            df_rec['distance'] = df_rec.apply(lambda row: geodist(coord1, row.latitude, row.longitude), axis=1)\n",
    "            \n",
    "            if df_rec['distance'].max() > drift_thresh:\n",
    "                drift_status.append(1)\n",
    "            else:\n",
    "                drift_status.append(0)\n",
    "            \n",
    "            start_ts = df_rec['timestamp'].iloc[0]\n",
    "            end_ts = df_rec['timestamp'].iloc[-1]\n",
    "            \n",
    "            df_list.append({\n",
    "                'folder': folder[-4:],\n",
    "                'Video_ID': file[-12:-4],\n",
    "                'start_timestamp': start_ts,\n",
    "                'end_timestamp': end_ts,\n",
    "                'File path': folder,\n",
    "                'minimum height': df_rec['altitude'].min(),\n",
    "                'maximum drift': df_rec['distance'].max(),\n",
    "                'Total frames': df_rec['frame'].max(),\n",
    "                'Frame time': df_rec['frame_time'].max(),\n",
    "                'maximum height': df_rec['altitude'].max()\n",
    "            })\n",
    "            \n",
    "            df_dict[folder[-4:] + '_' + file[-12:-4]] = df_rec.copy()\n",
    "    \n",
    "    df_day = pd.DataFrame(df_list)\n",
    "    df_day['drift_status'] = drift_status\n",
    "    df_day['Relay video'] = height_status\n",
    "    \n",
    "    def Frame_time_to_seconds(time_str):\n",
    "        time_obj = datetime.strptime(time_str, '%H:%M:%S,%f')\n",
    "        return time_obj.hour * 3600 + time_obj.minute * 60 + time_obj.second + time_obj.microsecond / 1000000\n",
    "    \n",
    "    df_day['Frame time'] = df_day['Frame time'].apply(Frame_time_to_seconds)\n",
    "    df_plot = df_day.copy()\n",
    "    \n",
    "    return df_day, df_plot, df_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def rearrange_columns(df_day):\n",
    "    \n",
    "    \"\"\"\n",
    "    Rearranges and splits certain columns\n",
    "    Args:\n",
    "        df_day : dataframe of the session\n",
    "        \n",
    "    Return:\n",
    "        df_day : Updated dataframe of the session\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace backslashes with forward slashes in the 'File path' column\n",
    "    df_day['File path'] = df_day['File path'].str.replace('\\\\', '/')\n",
    "    \n",
    "    # Create a new column 'Unique name' in df_day\n",
    "    df_day['Unique name'] = df_day['File path'].str.split('/').str[-3] + '_' + df_day['File path'].str.split('/').str[-2] + '_' + df_day['folder'] + '_' + df_day['Video_ID']\n",
    "    \n",
    "    # Extract first 2 letters into 'position' column\n",
    "    df_day['position'] = df_day['folder'].str[:2]\n",
    "    \n",
    "    # Extract last 2 letters into 'drone' column\n",
    "    df_day['drone'] = df_day['folder'].str[2:]\n",
    "    \n",
    "    # Rearrange the columns to match the desired position\n",
    "    df_day = df_day[['Video_ID', 'position', 'drone', 'start_timestamp', 'end_timestamp', 'Relay video', 'drift_status', 'maximum drift', 'maximum height', 'minimum height', 'File path', 'Unique name', 'Total frames', 'Frame time']]\n",
    "    \n",
    "    return df_day\n",
    "\n",
    "def finding_missing_data(df_day):\n",
    "    \n",
    "    \"\"\"\n",
    "    if the time difference between subsequent video files is between 1s and 10 minutes, It is reported as a miss click\n",
    "    \n",
    "        Args:\n",
    "            df_day : dataframe of the session\n",
    "        \n",
    "        Return:\n",
    "            df_day : Updated dataframe of the session\n",
    "            df_p1: dataframe of the session from position 1\n",
    "            df_p2: dataframe of the session from position 2\n",
    "            df_p3: dataframe of the session from position 3\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    positions = ['P1', 'P2', 'P3']\n",
    "\n",
    "    dfs = {}\n",
    "\n",
    "    for position in positions:\n",
    "        df_p = df_day[df_day['position'] == position]\n",
    "\n",
    "        # Remove the comma before microseconds\n",
    "        df_p['start_timestamp'] = df_p['start_timestamp'].str.replace(',', '')\n",
    "        df_p['end_timestamp'] = df_p['end_timestamp'].str.replace(',', '')\n",
    "\n",
    "        # Convert the timestamp columns to datetime type\n",
    "        df_p['start_timestamp'] = pd.to_datetime(df_p['start_timestamp'], format='%H:%M:%S%f')\n",
    "        df_p['end_timestamp'] = pd.to_datetime(df_p['end_timestamp'], format='%H:%M:%S%f')\n",
    "\n",
    "        # Shift the values in the \"end_timestamp\" column by one row\n",
    "        df_p['previous_end_timestamp'] = df_p['end_timestamp'].shift(1)\n",
    "\n",
    "        # Calculate the time difference and store the absolute value in the \"end_start_diff\" column\n",
    "        df_p['end_start_diff'] = (df_p['previous_end_timestamp'] - df_p['start_timestamp']).dt.total_seconds().abs()\n",
    "\n",
    "        # Remove the unnecessary column\n",
    "        df_p = df_p.drop('previous_end_timestamp', axis=1)\n",
    "\n",
    "        # To remove NAN of the last row\n",
    "        df_p['end_start_diff'] = df_p['end_start_diff'].fillna(0)\n",
    "\n",
    "        # Create the 'error' column and initialize it with 0\n",
    "        df_p['error'] = 0\n",
    "\n",
    "        # Set the 'error' values based on the condition\n",
    "        df_p.loc[(df_p['end_start_diff'] > 1) & (df_p['end_start_diff'] < 600), 'error'] = 1\n",
    "\n",
    "        # Convert the \"error\" column to integer type\n",
    "        df_p['error'] = df_p['error'].astype(int)\n",
    "\n",
    "        # Merge the data from error and Miss click\n",
    "\n",
    "        df_day.loc[df_p.index, 'Miss click'] = df_p['error'].values\n",
    "\n",
    "        # Remove the dates from the timestamp columns\n",
    "        df_p['start_timestamp'] = df_p['start_timestamp'].dt.time\n",
    "        df_p['end_timestamp'] = df_p['end_timestamp'].dt.time\n",
    "\n",
    "        # Store the DataFrame in the dictionary\n",
    "        dfs[position] = df_p.copy()\n",
    "\n",
    "    # Create separate DataFrames for P1, P2, and P3\n",
    "    df_p1 = dfs['P1']\n",
    "    df_p2 = dfs['P2']\n",
    "    df_p3 = dfs['P3']\n",
    "    \n",
    "    return df_day, df_p1, df_p2, df_p3\n",
    "\n",
    "def drone_number(df_p1, df_p2, df_p3):\n",
    "    \"\"\"\n",
    "    Drones are numbered depending on the starting time of the drones in each position. The other drone is marked as \n",
    "    the second drone\n",
    "    \n",
    "    Args:\n",
    "        df_p1: dataframe of the session from position 1\n",
    "        df_p2: dataframe of the session from position 2\n",
    "        df_p3: dataframe of the session from position 3\n",
    "        \n",
    "    Return:\n",
    "        first_drone_P1, first_drone_P2, first_drone_P3 : First drone that flew at each position\n",
    "        second_drone_P1, second_drone_P2, second_drone_P3 :Second frone that flew at each position\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    dfs = [df_p1, df_p2, df_p3]\n",
    "\n",
    "    # Lists to store first and second drones for each position\n",
    "    first_drones = []\n",
    "    second_drones = []\n",
    "\n",
    "    # Iterate through each DataFrame for P1, P2, and P3\n",
    "    for i, df_p in enumerate(dfs):\n",
    "        # Find the row with the lowest value in the 'start_timestamp' column\n",
    "        lowest_start_time = df_p['start_timestamp'].min()\n",
    "        lowest_start_row = df_p[df_p['start_timestamp'] == lowest_start_time]\n",
    "\n",
    "        # Extract the value in the 'drone' column from the lowest start time row\n",
    "        first_drone = lowest_start_row['drone'].values[0]\n",
    "        first_drones.append(first_drone)\n",
    "\n",
    "        # Find the second drone for each position\n",
    "        second_drone = df_p[df_p['drone'] != first_drone]['drone'].values[0]\n",
    "        second_drones.append(second_drone)\n",
    "\n",
    "    # Store the first drones for P1, P2, and P3 as separate variables\n",
    "    first_drone_P1 = first_drones[0]\n",
    "    first_drone_P2 = first_drones[1]\n",
    "    first_drone_P3 = first_drones[2]\n",
    "\n",
    "    # Store the second drones for P1, P2, and P3 as separate variables\n",
    "    second_drone_P1 = second_drones[0]\n",
    "    second_drone_P2 = second_drones[1]\n",
    "    second_drone_P3 = second_drones[2]\n",
    "    \n",
    "    return first_drone_P1, first_drone_P2, first_drone_P3, second_drone_P1, second_drone_P2, second_drone_P3\n",
    "\n",
    "\n",
    "def sortieid(df_day, first_drone_P1, first_drone_P2, first_drone_P3, second_drone_P1, second_drone_P2, second_drone_P3):\n",
    "    \n",
    "    \"\"\"\n",
    "    Column created for sortie id by considering the drone number and difference between the start and end time of consecutive\n",
    "    drones\n",
    "\n",
    "    Args:\n",
    "        df_day : dataframe of the session\n",
    "        first_drone_P1, first_drone_P2, first_drone_P3 : First drone that flew at each position\n",
    "        second_drone_P1, second_drone_P2, second_drone_P3 :Second frone that flew at each position\n",
    "        \n",
    "    Return: \n",
    "        df_day : Updated dataframe of the session \n",
    "    \n",
    "    \"\"\"\n",
    "    # For the first set of drones\n",
    "    positions = ['P1', 'P2', 'P3']\n",
    "    drones = [first_drone_P1, first_drone_P2, first_drone_P3]\n",
    "\n",
    "    dfs = {}\n",
    "\n",
    "    for position in positions:\n",
    "        for drone in drones:\n",
    "            df_p = df_day[(df_day['position'] == position) & (df_day['drone'] == drone)]\n",
    "\n",
    "            if not df_p.empty:  # Check if the DataFrame is not empty\n",
    "                # Rearrange df_p in ascending order of the data in the start_timestamp column\n",
    "                df_p = df_p.sort_values(by='start_timestamp', ascending=True)\n",
    "\n",
    "                # Remove the comma before microseconds\n",
    "                df_p['start_timestamp'] = df_p['start_timestamp'].str.replace(',', '')\n",
    "                df_p['end_timestamp'] = df_p['end_timestamp'].str.replace(',', '')\n",
    "\n",
    "                # Convert the timestamp columns to datetime type\n",
    "                df_p['start_timestamp'] = pd.to_datetime(df_p['start_timestamp'], format='%H:%M:%S%f')\n",
    "                df_p['end_timestamp'] = pd.to_datetime(df_p['end_timestamp'], format='%H:%M:%S%f')\n",
    "\n",
    "                # Shift the values in the \"start_timestamp\" column by one row\n",
    "                df_p['previous_end_timestamp'] = df_p['end_timestamp'].shift(1)\n",
    "\n",
    "                # Calculate the time difference and store the absolute value in the \"end_start_diff\" column\n",
    "                df_p['end_start_diff'] = (df_p['start_timestamp'] - df_p['previous_end_timestamp']).dt.total_seconds().abs()\n",
    "\n",
    "                # Remove the unnecessary column\n",
    "                df_p = df_p.drop('previous_end_timestamp', axis=1)\n",
    "\n",
    "                # To remove NAN of the last row\n",
    "                df_p['end_start_diff'] = df_p['end_start_diff'].fillna(0)\n",
    "\n",
    "                # FINDING THE SORTIE NUMBER\n",
    "                # Initialize the sortie column with 1\n",
    "                df_p['sortie'] = 0\n",
    "\n",
    "                # Set the sortie values based on the condition\n",
    "                sortie_count = 0\n",
    "                for index, row in df_p.iterrows():\n",
    "                    if pd.notnull(row['end_start_diff']) and row['end_start_diff'] > 600:\n",
    "                        sortie_count += 2\n",
    "                    df_p.at[index, 'sortie'] = sortie_count + 1\n",
    "\n",
    "\n",
    "                # Convert the \"sortie\" column to integer type\n",
    "                df_p['sortie'] = df_p['sortie'].astype(int)\n",
    "\n",
    "                # Merge the data from \"sortie\" column of df_p to \"flight number\" column of df_day\n",
    "                df_day.loc[df_p.index, 'flight number'] = df_p['sortie'].values\n",
    "\n",
    "                # Remove the dates from the timestamp columns\n",
    "                df_p['start_timestamp'] = df_p['start_timestamp'].dt.time\n",
    "                df_p['end_timestamp'] = df_p['end_timestamp'].dt.time\n",
    "\n",
    "                # Store the DataFrame in the dictionary\n",
    "                dfs[(position, drone)] = df_p.copy()\n",
    "\n",
    "    #For the second set of drones\n",
    "    positions = ['P1', 'P2', 'P3']\n",
    "    drones = [second_drone_P1, second_drone_P2, second_drone_P3]\n",
    "\n",
    "    dfs = {}\n",
    "\n",
    "    for position in positions:\n",
    "        for drone in drones:\n",
    "            df_p = df_day[(df_day['position'] == position) & (df_day['drone'] == drone)]\n",
    "\n",
    "            if not df_p.empty:  # Check if the DataFrame is not empty\n",
    "                # Rearrange df_p in ascending order of the data in the start_timestamp column\n",
    "                df_p = df_p.sort_values(by='start_timestamp', ascending=True)\n",
    "\n",
    "                # Remove the comma before microseconds\n",
    "                df_p['start_timestamp'] = df_p['start_timestamp'].str.replace(',', '')\n",
    "                df_p['end_timestamp'] = df_p['end_timestamp'].str.replace(',', '')\n",
    "\n",
    "                # Convert the timestamp columns to datetime type\n",
    "                df_p['start_timestamp'] = pd.to_datetime(df_p['start_timestamp'], format='%H:%M:%S%f')\n",
    "                df_p['end_timestamp'] = pd.to_datetime(df_p['end_timestamp'], format='%H:%M:%S%f')\n",
    "\n",
    "                # Shift the values in the \"start_timestamp\" column by one row\n",
    "                df_p['previous_end_timestamp'] = df_p['end_timestamp'].shift(1)\n",
    "\n",
    "                # Calculate the time difference and store the absolute value in the \"end_start_diff\" column\n",
    "                df_p['end_start_diff'] = (df_p['start_timestamp'] - df_p['previous_end_timestamp']).dt.total_seconds().abs()\n",
    "\n",
    "                # Remove the unnecessary column\n",
    "                df_p = df_p.drop('previous_end_timestamp', axis=1)\n",
    "\n",
    "                # To remove NAN of the last row\n",
    "                df_p['end_start_diff'] = df_p['end_start_diff'].fillna(0)\n",
    "\n",
    "                # FINDING THE SORTIE NUMBER\n",
    "                # Initialize the sortie column with 1\n",
    "                df_p['sortie'] = 0\n",
    "\n",
    "                # Set the sortie values based on the condition\n",
    "                sortie_count = 0\n",
    "                for index, row in df_p.iterrows():\n",
    "                    if pd.notnull(row['end_start_diff']) and row['end_start_diff'] > 600:\n",
    "                        sortie_count += 2\n",
    "                    df_p.at[index, 'sortie'] = sortie_count + 2\n",
    "\n",
    "\n",
    "                # Convert the \"sortie\" column to integer type\n",
    "                df_p['sortie'] = df_p['sortie'].astype(int)\n",
    "\n",
    "                # Merge the data from \"sortie\" column of df_p to \"flight number\" column of df_day\n",
    "                df_day.loc[df_p.index, 'flight number'] = df_p['sortie'].values\n",
    "\n",
    "                # Remove the dates from the timestamp columns\n",
    "                df_p['start_timestamp'] = df_p['start_timestamp'].dt.time\n",
    "                df_p['end_timestamp'] = df_p['end_timestamp'].dt.time\n",
    "\n",
    "                # Store the DataFrame in the dictionary\n",
    "                dfs[(position, drone)] = df_p.copy()                \n",
    "    return df_day\n",
    "                \n",
    "def start_end_time(df_day, df_p1, df_p2, df_p3):\n",
    "    \"\"\"\n",
    "    calculates the start time and end time by comparing the lowest and highest value in the start and end time of drones at each \n",
    "    positions\n",
    "    \n",
    "    Args:\n",
    "        df_day : dataframe of the session\n",
    "        df_p1: dataframe of the session from position 1\n",
    "        df_p2: dataframe of the session from position 2\n",
    "        df_p3: dataframe of the session from position 3\n",
    "    \n",
    "    Return:\n",
    "        df_day : Updated dataframe of the session\n",
    "        common_start_time: Global start time of the session\n",
    "        common_end_time  : Global end time of the session\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #FINDING COMMON START AND END TIME POINT AND PRINTING IN CSV\n",
    "    # Create a list to hold the start times of all three DataFrames\n",
    "    start_times = []\n",
    "\n",
    "    # Loop through each DataFrame and get the maximum value of the first row's start_timestamp column\n",
    "    for df in [df_p1, df_p2, df_p3]:\n",
    "        min_start_time = df['start_timestamp'].min()\n",
    "        start_times.append(min_start_time)\n",
    "\n",
    "\n",
    "    # Find the maximum value among the three common start times\n",
    "    common_start_time = max(start_times)\n",
    "\n",
    "    # Create a list to hold the end times of all three DataFrames\n",
    "    end_times = []\n",
    "\n",
    "    # Loop through each DataFrame and get the minimum value of the last row's end_timestamp column\n",
    "    for df in [df_p1, df_p2, df_p3]:\n",
    "        max_end_time = df['end_timestamp'].max()\n",
    "        end_times.append(max_end_time)\n",
    "\n",
    "    # Find the minimum value among the three common end times\n",
    "    common_end_time = min(end_times)\n",
    "\n",
    "    # Assign values to the first row of the new columns\n",
    "    df_day.loc[0, 'Global start time'] = common_start_time\n",
    "    df_day.loc[0, 'Global end time'] = common_end_time\n",
    "\n",
    "    #Assign 0 to rest of the rows\n",
    "    df_day['Global start time'].iloc[1:] = pd.to_datetime(0)\n",
    "    df_day['Global end time'].iloc[1:] = pd.to_datetime(0)\n",
    "\n",
    "    # Convert 'Common start time' and 'Common end time' columns to datetime\n",
    "    df_day['Global start time'] = pd.to_datetime(df_day['Global start time'].astype(str))\n",
    "    df_day['Global end time'] = pd.to_datetime(df_day['Global end time'].astype(str))\n",
    "    df_day.loc[1:, 'Global start time'] = pd.to_datetime(0)\n",
    "    df_day.loc[1:, 'Global end time'] = pd.to_datetime(0)\n",
    "\n",
    "    # Remove date part from 'Common start time' column and 'Common end time' column where value is not 0\n",
    "    df_day['Global start time'] = df_day['Global start time'].apply(lambda x: x.time() if type(x) == pd.Timestamp else x)\n",
    "    df_day['Global end time'] = df_day['Global end time'].apply(lambda x: x.time() if type(x) == pd.Timestamp else x)\n",
    "\n",
    "    #TO MAKE SURE CSV FILE IS NOT ROUNDED UP FOR COMMON START AND END TIME\n",
    "\n",
    "    # Function to format time strings to \"hours:minutes:seconds,microseconds\" format\n",
    "    def format_common_time(time_obj):\n",
    "        time_str = str(time_obj)  # Convert datetime.time object to string\n",
    "        hours, minutes, seconds = time_str.split(\":\")\n",
    "\n",
    "        # Split the seconds part into seconds and microseconds\n",
    "        seconds_part = seconds.split(\".\")\n",
    "        seconds = seconds_part[0]\n",
    "        microseconds = seconds_part[1] if len(seconds_part) > 1 else '000000'\n",
    "        microseconds = microseconds.ljust(6, \"0\")  # Pad zeros if needed\n",
    "\n",
    "        formatted_time = f\"{hours}:{minutes}:{seconds},{microseconds}\"\n",
    "        return formatted_time\n",
    "\n",
    "    # Format the time values in the columns\n",
    "    df_day['Global start time'] = df_day['Global start time'].apply(format_common_time)\n",
    "    df_day['Global end time'] = df_day['Global end time'].apply(format_common_time)\n",
    "\n",
    "\n",
    "    # Set all rows from index 1 onwards to '00:00:00,000000' in the 'Common start time' column\n",
    "    df_day['Global start time'].iloc[1:] = '0'\n",
    "\n",
    "    # Set all rows from index 1 onwards to '00:00:00,000000' in the 'Common end time' column\n",
    "    df_day['Global end time'].iloc[1:] = '0'\n",
    "\n",
    "\n",
    "    print(common_start_time)\n",
    "    print(common_end_time)\n",
    "    \n",
    "    return df_day, common_start_time, common_end_time\n",
    "\n",
    "\n",
    "\n",
    "def start_end_file(df_day, df_p1, df_p2, df_p3, common_start_time, common_end_time ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds the start and end srt file by finding which srt file has the global start and end time  \n",
    "    \n",
    "        Args:\n",
    "            df_day : dataframe of the session\n",
    "            df_p1: dataframe of the session from position 1\n",
    "            df_p2: dataframe of the session from position 2\n",
    "            df_p3: dataframe of the session from position 3\n",
    "            common_start_time: Global start time of the session\n",
    "            common_end_time  : Global end time of the session\n",
    "        \n",
    "        \n",
    "        Return:\n",
    "            first_video_p1, first_video_p2, first_video_p3,: video names used later to call the files from the df_dict\n",
    "            last_video_p1, last_video_p2, last_video_p3: video names used later to call the files from the df_dict\n",
    "            fvp1, fvp2, fvp3 : First video of the session from each location\n",
    "            lvp1, lvp2, lvp3 : Last video of the session from each location\n",
    "            \n",
    "            \n",
    "    \"\"\"\n",
    "    # Assuming 'X' contains the time in the format \"17:01:43.728497\"\n",
    "    X = common_start_time\n",
    "\n",
    "    # Convert 'X' to a pandas Timestamp object for comparison\n",
    "    common_start_time_timestamp = pd.to_datetime(X, format=\"%H:%M:%S.%f\")\n",
    "\n",
    "    # Create a dictionary to store the dataframes and their corresponding variables\n",
    "    dataframes = {'df_p1': df_p1.copy(), 'df_p2': df_p2.copy(), 'df_p3': df_p3.copy()}\n",
    "\n",
    "    # Create variables to store the first video IDs\n",
    "    first_video_p1 = None\n",
    "    first_video_p2 = None\n",
    "    first_video_p3 = None\n",
    "\n",
    "    # Iterate over the dataframes\n",
    "    for df_name, df in dataframes.items():\n",
    "        # Convert the 'start_timestamp' and 'end_timestamp' columns in the current dataframe to pandas Timestamp objects\n",
    "        df['start_timestamp'] = pd.to_datetime(df['start_timestamp'], format=\"%H:%M:%S.%f\")\n",
    "        df['end_timestamp'] = pd.to_datetime(df['end_timestamp'], format=\"%H:%M:%S.%f\")\n",
    "\n",
    "        # Find the row where 'common_start_time_timestamp' falls within the 'start_timestamp' and 'end_timestamp' interval\n",
    "        selected_row = df[(df['start_timestamp'] <= common_start_time_timestamp) & (df['end_timestamp'] >= common_start_time_timestamp)]\n",
    "\n",
    "        # Check if any row was found and store the corresponding Video_ID in the appropriate variable\n",
    "        if not selected_row.empty:\n",
    "            if df_name == 'df_p1':\n",
    "                first_video_p1 = \"P1\" + selected_row['drone'].values[0]+\"_\"+selected_row['Video_ID'].values[0]\n",
    "                fvp1 = selected_row['Video_ID'].values[0]\n",
    "            elif df_name == 'df_p2':\n",
    "                first_video_p2 = \"P2\" + selected_row['drone'].values[0]+\"_\"+selected_row['Video_ID'].values[0]\n",
    "                fvp2 = selected_row['Video_ID'].values[0]\n",
    "            elif df_name == 'df_p3':\n",
    "                first_video_p3 = \"P3\" + selected_row['drone'].values[0]+\"_\"+selected_row['Video_ID'].values[0]\n",
    "                fvp3 = selected_row['Video_ID'].values[0]\n",
    "\n",
    "    #Finding the file name that contain the global end time\n",
    "\n",
    "\n",
    "    X = common_end_time\n",
    "\n",
    "    # Convert 'X' to a pandas Timestamp object for comparison\n",
    "    common_end_time_timestamp = pd.to_datetime(X, format=\"%H:%M:%S.%f\")\n",
    "\n",
    "    # Create a dictionary to store the dataframes and their corresponding variables\n",
    "    dataframes = {'df_p1': df_p1.copy(), 'df_p2': df_p2.copy(), 'df_p3': df_p3.copy()}\n",
    "\n",
    "    # Create variables to store the first video IDs\n",
    "    last_video_p1 = None\n",
    "    last_video_p2 = None\n",
    "    last_video_p3 = None\n",
    "\n",
    "    # Iterate over the dataframes\n",
    "    for df_name, df in dataframes.items():\n",
    "        # Convert the 'start_timestamp' and 'end_timestamp' columns in the current dataframe to pandas Timestamp objects\n",
    "        df['start_timestamp'] = pd.to_datetime(df['start_timestamp'], format=\"%H:%M:%S.%f\")\n",
    "        df['end_timestamp'] = pd.to_datetime(df['end_timestamp'], format=\"%H:%M:%S.%f\")\n",
    "\n",
    "        # Find the row where 'common_start_time_timestamp' falls within the 'start_timestamp' and 'end_timestamp' interval\n",
    "        selected_row = df[(df['start_timestamp'] <= common_end_time_timestamp) & (df['end_timestamp'] >= common_end_time_timestamp)]\n",
    "\n",
    "        # Check if any row was found and store the corresponding Video_ID in the appropriate variable\n",
    "        if not selected_row.empty:\n",
    "            if df_name == 'df_p1':\n",
    "                last_video_p1 =\"P1\" + selected_row['drone'].values[0]+\"_\"+selected_row['Video_ID'].values[0]\n",
    "                lvp1 = selected_row['Video_ID'].values[0]\n",
    "            elif df_name == 'df_p2':\n",
    "                last_video_p2 = \"P2\" + selected_row['drone'].values[0]+\"_\"+selected_row['Video_ID'].values[0]\n",
    "                lvp2 = selected_row['Video_ID'].values[0]\n",
    "            elif df_name == 'df_p3':\n",
    "                last_video_p3 =\"P3\" + selected_row['drone'].values[0]+\"_\"+selected_row['Video_ID'].values[0]\n",
    "                lvp3 = selected_row['Video_ID'].values[0]\n",
    "\n",
    "\n",
    "    \n",
    "    return first_video_p1, first_video_p2, first_video_p3, last_video_p1, last_video_p2, last_video_p3, fvp1, fvp2, fvp3, lvp1, lvp2, lvp3\n",
    "\n",
    "def start_end_frame(first_video_p1, \n",
    "                    first_video_p2,\n",
    "                    first_video_p3,\n",
    "                    last_video_p1,\n",
    "                    last_video_p2,\n",
    "                    last_video_p3,\n",
    "                    df_dict,\n",
    "                    common_start_time,\n",
    "                    common_end_time,\n",
    "                    df_p1,\n",
    "                    df_p2,\n",
    "                    df_p3,\n",
    "                    df_day,fvp1, fvp2, fvp3, lvp1, lvp2, lvp3\n",
    "                    \n",
    "                   ):\n",
    "    \"\"\"\n",
    "    Finds the exact frame of the global start and end time for each position\n",
    "    \n",
    "    Args:\n",
    "        df_day : dataframe of the session\n",
    "        df_p1: dataframe of the session from position 1\n",
    "        df_p2: dataframe of the session from position 2\n",
    "        df_p3: dataframe of the session from position 3\n",
    "        common_start_time: Global start time of the session\n",
    "        common_end_time  : Global end time of the session\n",
    "        first_video_p1, first_video_p2, first_video_p3,: video names used to call the the dataframe of\n",
    "        the first video files from the df_dict of each location\n",
    "        last_video_p1, last_video_p2, last_video_p3: video names used to call the the dataframe of\n",
    "        the last video files from the df_dict of each location\n",
    "        fvp1, fvp2, fvp3 : First video of the session from each location\n",
    "        lvp1, lvp2, lvp3 : Last video of the session from each location\n",
    "        \n",
    "    Return:\n",
    "        df_day : Updated dataframe of the session\n",
    "\"\"\"\n",
    " \n",
    "\n",
    "    #FOR FINDING THE FIRST FRAMES\n",
    "    import datetime\n",
    "\n",
    "    #FOR FINDING THE FIRST FRAMES\n",
    "\n",
    "    from datetime import datetime, date, time\n",
    "    # List of first_video_p values\n",
    "    first_video_p_list = [first_video_p1, first_video_p2, first_video_p3]\n",
    "\n",
    "    # Dictionary to store corresponding_frame for each first_video_p\n",
    "    corresponding_frame_dict = {}\n",
    "\n",
    "    # Loop through each first_video_p value\n",
    "    for first_video_p in first_video_p_list:\n",
    "        data_frame = df_dict.get(first_video_p)\n",
    "        df_fr = data_frame.copy()\n",
    "\n",
    "\n",
    "        df_fr['timestamp'] = df_fr['timestamp'].str.replace(',', '')\n",
    "        # Convert the timestamp columns to datetime type\n",
    "        df_fr['timestamp'] = pd.to_datetime(df_fr['timestamp'], format='%H:%M:%S%f')\n",
    "        # Remove the dates from the timestamp columns\n",
    "        df_fr['timestamp'] = df_fr['timestamp'].dt.time\n",
    "\n",
    "\n",
    "        def calculate_time_difference(row):\n",
    "            common_datetime = datetime.combine(date.today(), common_start_time)\n",
    "\n",
    "            timestamp_datetime = datetime.combine(date.today(), row['timestamp'])\n",
    "            time_difference = (timestamp_datetime - common_datetime).total_seconds()\n",
    "            return time_difference\n",
    "\n",
    "\n",
    "        df_fr['time_diff'] = df_fr.apply(calculate_time_difference, axis=1)\n",
    "\n",
    "\n",
    "        positive_time_diff_df = df_fr[df_fr['time_diff'] >= 0]\n",
    "\n",
    "        # Step 5: Find the row with the smallest positive time difference\n",
    "        min_positive_time_diff_row = positive_time_diff_df.loc[positive_time_diff_df['time_diff'].idxmin()]\n",
    "\n",
    "        # Step 6: Get the corresponding frame value\n",
    "        corresponding_frame = min_positive_time_diff_row['frame']\n",
    "\n",
    "        # Save corresponding_frame in the dictionary for the current first_video_p\n",
    "        corresponding_frame_dict[first_video_p] = corresponding_frame\n",
    "\n",
    "    # Extract corresponding_frame values from the dictionary and store in separate variables\n",
    "    first_frame_p1 = corresponding_frame_dict.get(first_video_p1)\n",
    "    first_frame_p2 = corresponding_frame_dict.get(first_video_p2)\n",
    "    first_frame_p3 = corresponding_frame_dict.get(first_video_p3)\n",
    "\n",
    "    # Print the corresponding_frame values for each first_video_p\n",
    "    print(\"Corresponding Frame for first_video_p1:\", first_frame_p1)\n",
    "    print(\"Corresponding Frame for first_video_p2:\", first_frame_p2)\n",
    "    print(\"Corresponding Frame for first_video_p3:\", first_frame_p3)\n",
    "    \n",
    "    #FOR FINDING THE LAST FRAMES# List of last_video_p values\n",
    "        #FOR FINDING THE LAST FRAMES# List of last_video_p values\n",
    "    from datetime import datetime, date, time\n",
    "    # List of last_video_p values\n",
    "    last_video_p_list = [last_video_p1, last_video_p2, last_video_p3]\n",
    "\n",
    "    # Dictionary to store corresponding_frame for each first_video_p\n",
    "    corresponding_frame_dict = {}\n",
    "\n",
    "    # Loop through each first_video_p value\n",
    "    for last_video_p in last_video_p_list:\n",
    "        data_frame = df_dict.get(last_video_p)\n",
    "        df_fr = data_frame.copy()\n",
    "\n",
    "\n",
    "        df_fr['timestamp'] = df_fr['timestamp'].str.replace(',', '')\n",
    "        # Convert the timestamp columns to datetime type\n",
    "        df_fr['timestamp'] = pd.to_datetime(df_fr['timestamp'], format='%H:%M:%S%f')\n",
    "        # Remove the dates from the timestamp columns\n",
    "        df_fr['timestamp'] = df_fr['timestamp'].dt.time\n",
    "\n",
    "        def calculate_time_difference(row):\n",
    "            common_datetime = datetime.combine(date.today(), common_end_time)\n",
    "\n",
    "            timestamp_datetime = datetime.combine(date.today(), row['timestamp'])\n",
    "            time_difference = (common_datetime - timestamp_datetime).total_seconds()\n",
    "            return time_difference\n",
    "\n",
    "        df_fr['time_diff'] = df_fr.apply(calculate_time_difference, axis=1)\n",
    "        positive_time_diff_df = df_fr[df_fr['time_diff'] >= 0]\n",
    "\n",
    "        # Step 5: Find the row with the smallest positive time difference\n",
    "        min_positive_time_diff_row = positive_time_diff_df.loc[positive_time_diff_df['time_diff'].idxmin()]\n",
    "\n",
    "        # Step 6: Get the corresponding frame value\n",
    "        corresponding_frame = min_positive_time_diff_row['frame']\n",
    "\n",
    "        # Save corresponding_frame in the dictionary for the current first_video_p\n",
    "        corresponding_frame_dict[last_video_p] = corresponding_frame\n",
    "\n",
    "    # Extract corresponding_frame values from the dictionary and store in separate variables\n",
    "    last_frame_p1 = corresponding_frame_dict.get(last_video_p1)\n",
    "    last_frame_p2 = corresponding_frame_dict.get(last_video_p2)\n",
    "    last_frame_p3 = corresponding_frame_dict.get(last_video_p3)\n",
    "\n",
    "    # Print the corresponding_frame values for each first_video_p\n",
    "    print(\"Corresponding Frame for last_video_p1:\", last_frame_p1)\n",
    "    print(\"Corresponding Frame for last_video_p2:\", last_frame_p2)\n",
    "    print(\"Corresponding Frame for last_video_p3:\", last_frame_p3)\n",
    "\n",
    "    #ASSIGNING STARTING AND ENDING FRAMES TO THE CSV FILE\n",
    "\n",
    "    positions = ['P1', 'P2', 'P3']\n",
    "\n",
    "    # Create a new DataFrame df_p1 with rows where 'Video_ID' is 'P1'\n",
    "    df_p1 = df_day[df_day['position'] == 'P1'].copy()\n",
    "    # Create a new DataFrame df_p1 with rows where 'Video_ID' is 'P2'\n",
    "    df_p2 = df_day[df_day['position'] == 'P2'].copy()\n",
    "    # Create a new DataFrame df_p1 with rows where 'Video_ID' is 'P3'\n",
    "    df_p3 = df_day[df_day['position'] == 'P3'].copy()\n",
    "\n",
    "    # Initialize 'start_frame' column to 0 for all DataFrames\n",
    "    for df_position in [df_p1, df_p2, df_p3]:\n",
    "        df_position['start_frame'] = 0\n",
    "\n",
    "    # Set 'start_frame' for specific 'Video_ID's in each DataFrame\n",
    "    df_p1.loc[df_p1[df_p1['Video_ID'] == fvp1].index, 'start_frame'] = first_frame_p1\n",
    "    df_p2.loc[df_p2[df_p2['Video_ID'] == fvp2].index, 'start_frame'] = first_frame_p2\n",
    "    df_p3.loc[df_p3[df_p3['Video_ID'] == fvp3].index, 'start_frame'] = first_frame_p3\n",
    "\n",
    "    # Iterate through positions and update the main dataframe 'df_day'\n",
    "    for position, df_position in zip(positions, [df_p1, df_p2, df_p3]):\n",
    "        # Update the main dataframe 'df_day' with the changes made in the current position's DataFrame\n",
    "        df_day.loc[df_position.index, 'Start Frame'] = df_position['start_frame'].values\n",
    "\n",
    "\n",
    "    positions = ['P1', 'P2', 'P3']\n",
    "\n",
    "    # Create a new DataFrame df_p1 with rows where 'Video_ID' is 'P1'\n",
    "    df_p1 = df_day[df_day['position'] == 'P1'].copy()\n",
    "    # Create a new DataFrame df_p1 with rows where 'Video_ID' is 'P2'\n",
    "    df_p2 = df_day[df_day['position'] == 'P2'].copy()\n",
    "    # Create a new DataFrame df_p1 with rows where 'Video_ID' is 'P3'\n",
    "    df_p3 = df_day[df_day['position'] == 'P3'].copy()\n",
    "\n",
    "    # Initialize 'start_frame' column to 0 for all DataFrames\n",
    "    for df_position in [df_p1, df_p2, df_p3]:\n",
    "        df_position['end_frame'] = 0\n",
    "\n",
    "    # Set 'start_frame' for specific 'Video_ID's in each DataFrame\n",
    "    df_p1.loc[df_p1[df_p1['Video_ID'] == lvp1].index, 'end_frame'] = last_frame_p1\n",
    "    df_p2.loc[df_p2[df_p2['Video_ID'] == lvp2].index, 'end_frame'] = last_frame_p2\n",
    "    df_p3.loc[df_p3[df_p3['Video_ID'] == lvp3].index, 'end_frame'] = last_frame_p3\n",
    "\n",
    "    # Iterate through positions and update the main dataframe 'df_day'\n",
    "    for position, df_position in zip(positions, [df_p1, df_p2, df_p3]):\n",
    "        # Update the main dataframe 'df_day' with the changes made in the current position's DataFrame\n",
    "        df_day.loc[df_position.index, 'End Frame'] = df_position['end_frame'].values\n",
    "    \n",
    "    return df_day\n",
    "\n",
    "\n",
    "def check_frame_drop(df_day):\n",
    "    \"\"\"\n",
    "    Compares the frame extracted from the srt file to the frames clalculated by multiplying flight time of each\n",
    "    flight with 30 (30fps)\n",
    "    \n",
    "    Args:\n",
    "        df_day : dataframe of the session\n",
    "        \n",
    "     Return:\n",
    "         df_day : Updated dataframe of the session\n",
    "         \n",
    "         \n",
    "    \"\"\"\n",
    "    \n",
    "    #Checking for frame drops\n",
    "    df_x = df_day.copy()\n",
    "\n",
    "    # Remove the comma before microseconds\n",
    "    df_x['start_timestamp'] = df_x['start_timestamp'].str.replace(',', '')\n",
    "    df_x['end_timestamp'] = df_x['end_timestamp'].str.replace(',', '')\n",
    "\n",
    "        # Convert the timestamp columns to datetime type\n",
    "    df_x['start_timestamp'] = pd.to_datetime(df_x['start_timestamp'], format='%H:%M:%S%f')\n",
    "    df_x['end_timestamp'] = pd.to_datetime(df_x['end_timestamp'], format='%H:%M:%S%f')\n",
    "\n",
    "    # Calculate the time difference and store the absolute value in the \"end_start_diff\" column\n",
    "    df_x['Global TOF'] = (df_x['end_timestamp'] - df_x['start_timestamp']).dt.total_seconds().abs()\n",
    "    #30 fps video\n",
    "    df_x['Required frames'] = df_x['Global TOF'] * 30\n",
    "\n",
    "    # Create the 'Frame drop' column and initialize it with 0\n",
    "    df_x['Frame drop'] = 0\n",
    "\n",
    "    # Set the 'frame drop' values based on the condition\n",
    "    df_x.loc[(df_x['Required frames'] - df_x['Total frames'] > 5) , 'Frame drop'] = 1\n",
    "\n",
    "    # Merge the data\n",
    "    df_day.loc[df_x.index, 'Frame drop'] = df_x['Frame drop'].values\n",
    "    df_day.loc[df_x.index, 'Global TOF'] = df_x['Global TOF'].values\n",
    "    df_day.loc[df_x.index, 'Required frames'] = df_x['Required frames'].values\n",
    "    \n",
    "    return df_day\n",
    "\n",
    "\n",
    "def save_csv(df_day):\n",
    "\n",
    "    # Rearrange the columns to match the desired position\n",
    "    df_day = df_day[['Unique name', 'Video_ID','position', 'drone','Total frames', 'start_timestamp', 'end_timestamp', 'flight number', 'Relay video',  'maximum drift'  , 'drift_status', 'Miss click', 'maximum height', 'minimum height','Global start time','Global end time', 'Start Frame', 'End Frame','Frame drop','Frame time', 'Global TOF','Required frames', 'File path']]\n",
    "\n",
    "    \n",
    "    input_string = df_day['Unique name'][0]  # Replace with the actual input string\n",
    "    name = '_'.join(input_string.split('_')[:3])\n",
    "\n",
    "\n",
    "    df_day.to_csv(f'{name}.csv', index=False) # Set index=False if you don't want to save the index column\n",
    "    return df_day, name\n",
    "\n",
    "def save_txt(df_day, name):\n",
    "    #CREATES TXT FILE IF ANY ERROR FOUND IN DRIFT OR MISS CLICK\n",
    "   \n",
    "    # Filter rows where 'drift_status' or 'Miss click' is equal to 1\n",
    "    filtered_df = df_day[(df_day['drift_status'] == 1) | (df_day['Miss click'] == 1) | (df_day['minimum height'] < 78) | (df_day['Frame drop'] == 1)]\n",
    "\n",
    "    # If there are any rows with 'drift_status' or 'Miss click' equal to 1, create the text file\n",
    "    if not filtered_df.empty:\n",
    "        file_name = f\"{name}_summary.txt\"\n",
    "\n",
    "        # Create the text file and write the content\n",
    "        with open(file_name, 'w') as f:\n",
    "            f.write(\"Summary of the errors\\n\")\n",
    "            for index, row in filtered_df.iterrows():\n",
    "                drift = row['maximum drift']\n",
    "                video_id = row['Unique name']\n",
    "                height = row['minimum height']\n",
    "                if row['drift_status'] == 1:\n",
    "                    f.write(f\"Drift found at the {video_id} of value {drift}m\\n\")\n",
    "                if row['Miss click'] == 1:\n",
    "                    f.write(f\"Miss click found at the {video_id}\\n\")\n",
    "                if row['minimum height'] < 78:\n",
    "                    f.write(f\"Drone flew below 78m at the {video_id}, height = {height} m \\n\")\n",
    "                if row['Frame drop'] == 1:\n",
    "                    f.write(f\"Frame drop at the {video_id}\\n\") \n",
    "\n",
    "\n",
    "def plot(df_plot):\n",
    "    \n",
    "    # Convert timestamps to python datetime %H:%M:%S,%f format\n",
    "    df_plot['start_timestamp'] = df_plot['start_timestamp'].str[:-4] + df_plot['start_timestamp'].str[-3:]\n",
    "    df_plot['end_timestamp'] = df_plot['end_timestamp'].str[:-4] + df_plot['end_timestamp'].str[-3:]\n",
    "\n",
    "    df_plot['start_timestamp'] = pd.to_datetime(df_plot['start_timestamp'], format= '%H:%M:%S,%f')#.dt.time\n",
    "    df_plot['end_timestamp'] = pd.to_datetime(df_plot['end_timestamp'], format='%H:%M:%S,%f')#.dt.time\n",
    "\n",
    "    # Generate a range of timestamps using the minimum start timestamp and maximum end timestamp, with a 2-second frequency\n",
    "    x_values = pd.date_range(df_plot['start_timestamp'].min(), df_plot['end_timestamp'].max(), freq='2S')\n",
    "\n",
    "    # Initialize an empty list to store data for each drone at each timestamp\n",
    "    drone_id = []\n",
    "\n",
    "    # Iterate over each timestamp in the x_values range\n",
    "    for x in x_values:\n",
    "        # For each drone, count the number of entries where the start_timestamp is less than or equal to the current timestamp, \n",
    "        # the end_timestamp is greater than the current timestamp, and the folder contains the drone ID\n",
    "        drone_id.append([\n",
    "            x, \n",
    "            len(df_plot.loc[(df_plot['start_timestamp'] <= x) & (df_plot['end_timestamp'] > x) & (df_plot['folder'].str.contains('D1')),:]),\n",
    "            len(df_plot.loc[(df_plot['start_timestamp'] <= x) & (df_plot['end_timestamp'] > x) & (df_plot['folder'].str.contains('D2')),:]),\n",
    "            len(df_plot.loc[(df_plot['start_timestamp'] <= x) & (df_plot['end_timestamp'] > x) & (df_plot['folder'].str.contains('D3')),:]),\n",
    "            len(df_plot.loc[(df_plot['start_timestamp'] <= x) & (df_plot['end_timestamp'] > x) & (df_plot['folder'].str.contains('D4')),:]),\n",
    "            len(df_plot.loc[(df_plot['start_timestamp'] <= x) & (df_plot['end_timestamp'] > x) & (df_plot['folder'].str.contains('D5')),:]),\n",
    "            len(df_plot.loc[(df_plot['start_timestamp'] <= x) & (df_plot['end_timestamp'] > x) & (df_plot['folder'].str.contains('D6')),:])\n",
    "        ])\n",
    "\n",
    "    # Create a pandas DataFrame from the drone_id list\n",
    "    t = pd.DataFrame(drone_id)\n",
    "\n",
    "    # Create a figure with 3 subplots and a shared x-axis\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 5), sharex=True)\n",
    "\n",
    "    # Plot data of drones D1 and D2 on position P1\n",
    "    ax1.plot(t[0], t[1], c='blue')\n",
    "    ax1.plot(t[0], t[2], c='red')\n",
    "\n",
    "    # Plot data of drones D3 and D4 on position P2\n",
    "    ax2.plot(t[0], t[3], c='blue')\n",
    "    ax2.plot(t[0], t[4], c='red')\n",
    "\n",
    "    # Plot data of drones D5 and D6 on position P3\n",
    "    ax3.plot(t[0], t[5], c='blue')\n",
    "    ax3.plot(t[0], t[6], c='red')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()   \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48d9733",
   "metadata": {},
   "outputs": [],
   "source": [
    "D:/MELA/Test Dataset SRT/20230308/SE_Lek1/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
