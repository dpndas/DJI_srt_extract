{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893fe6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def clean_annotation(csv_file_path):\n",
    "    def process_csv(file_path):\n",
    "        # Define the column headers\n",
    "        headers = ['frame', 'classid', 'id', 'x1', 'y1', 'width', 'height', 'a', 'b', 'c', 'd']\n",
    "        \n",
    "        # Read the CSV file into a DataFrame and assign the headers\n",
    "        df_in = pd.read_csv(file_path, header=None, names=headers)\n",
    "        \n",
    "        df_in.sort_values(by='frame', inplace=True)                \n",
    "        # Calculate 'area' column\n",
    "        df_in['area'] = df_in['width'] * df_in['height']\n",
    "        return df_in \n",
    "    \n",
    "    #find classid \n",
    "    def class_error(df):\n",
    "        # Create a new column 'classid_error' and initialize it with 0\n",
    "        df['classid_error'] = 0\n",
    "\n",
    "        # Function to update 'classid_error' column based on 'classid' column\n",
    "        def update_classid_error(row):\n",
    "            if row['classid'] == -1:\n",
    "                return 1\n",
    "            else:\n",
    "                return row['classid_error']\n",
    "\n",
    "        # Apply the update_classid_error function to each row\n",
    "        df['classid_error'] = df.apply(update_classid_error, axis=1)\n",
    "\n",
    "        df['classid_error_frame'] = 0\n",
    "\n",
    "        # Find frames with 'classid_error' entry of 1\n",
    "        frames_with_classid_error = df[df['classid_error'] == 1]['frame'].unique()\n",
    "\n",
    "        # Update 'classid_error_frame' column for the identified frames\n",
    "        df.loc[df['frame'].isin(frames_with_classid_error), 'classid_error_frame'] = 1\n",
    "        \n",
    "\n",
    "        # Print frames with classid errors\n",
    "        print(\"Frames with classid errors:\", frames_with_classid_error)\n",
    "        # Define a function to calculate IoU between two bounding boxes\n",
    "        def calculate_iou(box1, box2):\n",
    "            x1, y1, w1, h1 = box1\n",
    "            x2, y2, w2, h2 = box2\n",
    "\n",
    "            intersection_x1 = max(x1, x2)\n",
    "            intersection_y1 = max(y1, y2)\n",
    "            intersection_x2 = min(x1 + w1, x2 + w2)\n",
    "            intersection_y2 = min(y1 + h1, y2 + h2)\n",
    "\n",
    "            intersection_area = max(0, intersection_x2 - intersection_x1) * max(0, intersection_y2 - intersection_y1)\n",
    "            union_area = w1 * h1 + w2 * h2 - intersection_area\n",
    "\n",
    "            return intersection_area / union_area\n",
    "\n",
    "        # Find frames with 'classid_error' entry of 1\n",
    "        frames_with_classid_error = df[df['classid_error'] == 1]['frame'].unique()\n",
    "\n",
    "        for frame in frames_with_classid_error:\n",
    "            error_frame_rows = df[(df['frame'] == frame) & (df['classid_error'] == 1)]\n",
    "            previous_frame = df[df['frame'] == frame - 1]\n",
    "\n",
    "            for index, error_row in error_frame_rows.iterrows():\n",
    "                max_iou = -1  # Initialize max IoU to a non-positive value\n",
    "                corrected_classid = None\n",
    "                corrected_id = None\n",
    "\n",
    "                # Extract coordinates of the error row\n",
    "                error_box = (error_row['x1'], error_row['y1'], error_row['width'], error_row['height'])\n",
    "\n",
    "                # Iterate through rows of the previous frame\n",
    "                for prev_index, prev_row in previous_frame.iterrows():\n",
    "                    prev_box = (prev_row['x1'], prev_row['y1'], prev_row['width'], prev_row['height'])\n",
    "\n",
    "                    # Calculate IoU between the error row and the previous row\n",
    "                    iou = calculate_iou(error_box, prev_box)\n",
    "\n",
    "                    if iou > max_iou:\n",
    "                        max_iou = iou\n",
    "                        corrected_classid = prev_row['classid']\n",
    "                        corrected_id = prev_row['id']\n",
    "\n",
    "                # Update the error row with the classid and id from the row with maximum IoU\n",
    "                df.at[index, 'classid'] = corrected_classid\n",
    "                df.at[index, 'id'] = corrected_id\n",
    "\n",
    "        return df\n",
    "  \n",
    "    \n",
    "    #Finding duplicate frames\n",
    "    def duplicates(df):\n",
    "        # Create a new column 'duplicates' indicating if a row is a duplicate\n",
    "        df['duplicates'] = df.groupby(['frame', 'classid'])['id'].transform(lambda x: x.duplicated(keep=False).astype(int))\n",
    "        duplicate_statements = []\n",
    "        # Find unique frames with duplicates\n",
    "        frames_with_duplicates = df.loc[df['duplicates'] == 1, 'frame'].unique()\n",
    "\n",
    "        # Create 'duplicate_frame' column and set values based on 'frame' and 'frames_with_duplicates'\n",
    "        df['duplicate_frame'] = df['frame'].apply(lambda x: 1 if x in frames_with_duplicates else 0)\n",
    "\n",
    "        for index, row in df[df['duplicates'] == 1].iterrows(): \n",
    "            statement = f\"ID {row['id']} (Class {row['classid']}) has duplicates in frame {row['frame']}\"\n",
    "            duplicate_statements.append(statement)\n",
    "\n",
    "\n",
    "        # Print frames with duplicates\n",
    "        print(\"Frames with Duplicates:\", frames_with_duplicates)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        frames_with_duplicates = df.loc[df['duplicates'] == 1, 'frame'].unique()\n",
    "\n",
    "        # Step 2: Create a list to store the corresponding unique entries of the frame column\n",
    "        unique_frames = []\n",
    "\n",
    "        # Iterate through frames_with_duplicates and append unique entries to unique_frames list\n",
    "        for frame in frames_with_duplicates:\n",
    "            unique_frame = df.loc[(df['frame'] == frame) & (df['duplicates'] == 1), 'frame'].iloc[0]\n",
    "            unique_frames.append(unique_frame)\n",
    "\n",
    "        for frame in unique_frames:\n",
    "            frame_data = df[df['frame'] == frame]\n",
    "\n",
    "            # Check if there are more than one duplicate rows in the frame\n",
    "            if len(frame_data) > 1:\n",
    "                min_distance = float('inf')\n",
    "                min_distance_duplicate_index = None\n",
    "\n",
    "                # Iterate through all combinations of duplicate rows\n",
    "                for index1, duplicate_row1 in frame_data.iterrows():\n",
    "                    for index2, duplicate_row2 in frame_data.iterrows():\n",
    "                        if index1 != index2:\n",
    "                            x1 = duplicate_row1['x1']\n",
    "                            y1 = duplicate_row1['y1']\n",
    "                            x2 = duplicate_row2['x1']\n",
    "                            y2 = duplicate_row2['y1']\n",
    "\n",
    "                            # Calculate the Euclidean distance between the coordinates of the two duplicates\n",
    "                            distance = math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
    "\n",
    "                            if distance < min_distance:\n",
    "                                min_distance = distance\n",
    "                                min_distance_duplicate_index = index1\n",
    "\n",
    "                # Check if the minimum distance is greater than 100\n",
    "                if min_distance > 100:\n",
    "                    #remove dupliactes based on the distance\n",
    "                    import pandas as pd\n",
    "\n",
    "                    # Read the DataFrame from your CSV file or use the existing DataFrame df_in\n",
    "                    # df_in = pd.read_csv('your_csv_file.csv')\n",
    "\n",
    "                    # Step 1: Find unique frames with duplicates\n",
    "                    frames_with_duplicates = df.loc[df['duplicates'] == 1, 'frame'].unique()\n",
    "\n",
    "                    # Step 2: Create a list to store the corresponding unique entries of the frame column\n",
    "                    unique_frames = []\n",
    "\n",
    "                    # Iterate through frames_with_duplicates and append unique entries to unique_frames list\n",
    "                    for frame in frames_with_duplicates:\n",
    "                        unique_frame = df.loc[(df_in['frame'] == frame) & (df['duplicates'] == 1), 'frame'].iloc[0]\n",
    "                        unique_frames.append(unique_frame)\n",
    "\n",
    "                    for frame in unique_frames:\n",
    "                        frame_data = df[df_in['frame'] == frame]\n",
    "                        prev_frame = frame - 1\n",
    "\n",
    "                        for classid, individual_id in frame_data.groupby(['classid', 'id']):\n",
    "                            duplicate_rows = individual_id[individual_id['duplicates'] == 1]\n",
    "                            if len(duplicate_rows) > 1:\n",
    "                                min_distance = float('inf')\n",
    "                                min_distance_duplicate_index = None\n",
    "\n",
    "                                for index, duplicate_row in duplicate_rows.iterrows():\n",
    "                                    id_to_compare = duplicate_row['id']\n",
    "                                    prev_frame_entry = df_in[(df['frame'] == prev_frame) & (df['id'] == id_to_compare)]\n",
    "\n",
    "                                    if not prev_frame_entry.empty:\n",
    "                                        x = duplicate_row['x1']\n",
    "                                        y = duplicate_row['y1']\n",
    "\n",
    "                                        prev_x = prev_frame_entry['x1'].values[0]\n",
    "                                        prev_y = prev_frame_entry['y1'].values[0]\n",
    "\n",
    "                                        # Calculate the Euclidean distance between the coordinates\n",
    "                                        distance = ((x - prev_x) ** 2 + (y - prev_y) ** 2) ** 0.5\n",
    "\n",
    "                                        if distance < min_distance:\n",
    "                                            min_distance = distance\n",
    "                                            min_distance_duplicate_index = index\n",
    "\n",
    "                                # Drop the duplicate rows that do not have the smallest distance\n",
    "                                duplicate_rows_to_drop = duplicate_rows[duplicate_rows.index != min_distance_duplicate_index]\n",
    "                                df.drop(duplicate_rows_to_drop.index, inplace=True)\n",
    "\n",
    "                else:                       \n",
    "                    frames_with_duplicates = df.loc[df['duplicates'] == 1, 'frame'].unique()\n",
    "\n",
    "                    # Step 2: Create a list to store the corresponding unique entries of the frame column\n",
    "                    unique_frames = []\n",
    "\n",
    "                    # Iterate through frames_with_duplicates and append unique entries to unique_frames list\n",
    "                    for frame in frames_with_duplicates:\n",
    "                        unique_frame = df.loc[(df['frame'] == frame) & (df['duplicates'] == 1), 'frame'].iloc[0]\n",
    "                        unique_frames.append(unique_frame)\n",
    "\n",
    "                    # Step 3: Remove duplicates with smaller area for each unique frame and id combination\n",
    "                    for frame in unique_frames:\n",
    "                        frame_data = df[df_in['frame'] == frame]\n",
    "                        prev_frame = frame - 1\n",
    "\n",
    "                        for classid, individual_id in frame_data.groupby(['classid', 'id']):\n",
    "                            duplicate_rows = individual_id[individual_id['duplicates'] == 1]\n",
    "                            if len(duplicate_rows) > 1:\n",
    "                                min_area_difference = float('inf')\n",
    "                                min_area_duplicate_index = None\n",
    "\n",
    "                                for index, duplicate_row in duplicate_rows.iterrows():\n",
    "                                    id_to_compare = duplicate_row['id']\n",
    "                                    prev_frame_entry = df[(df['frame'] == prev_frame) & (df_in['id'] == id_to_compare)]\n",
    "\n",
    "                                    if not prev_frame_entry.empty:\n",
    "                                        area_difference = abs(duplicate_row['area'] - prev_frame_entry['area'].values[0])\n",
    "                                        if area_difference < min_area_difference:\n",
    "                                            min_area_difference = area_difference\n",
    "                                            min_area_duplicate_index = index\n",
    "\n",
    "                                # Drop the duplicate row with the larger area\n",
    "                                duplicate_rows_to_drop = duplicate_rows[duplicate_rows.index != min_area_duplicate_index]\n",
    "                                df.drop(duplicate_rows_to_drop.index, inplace=True)\n",
    "\n",
    "        return df    \n",
    "\n",
    "        \n",
    "    def save_dataframe_to_csv(df, input_csv_file_path):\n",
    "        columns_to_drop = ['duplicates', 'duplicate_frame', 'classid_error', 'classid_error_frame','area']\n",
    "        # Drop the specified columns\n",
    "        df = df.drop(columns=columns_to_drop)\n",
    "        # Extract the directory path from the input CSV file's path\n",
    "        directory_path = os.path.dirname(input_csv_file_path)\n",
    "        # Extract the file name without extension from the input CSV file's path\n",
    "        file_name_without_extension = os.path.splitext(os.path.basename(input_csv_file_path))[0]\n",
    "        # Define the CSV file path for saving in the same directory as the input file\n",
    "        csv_file_path = os.path.join(directory_path, f'Edited_{file_name_without_extension}.csv')\n",
    "        # Save the DataFrame to CSV without headers\n",
    "        df.to_csv(csv_file_path, index=False, header=False)\n",
    "\n",
    "        return csv_file_path\n",
    "\n",
    "    df_in = process_csv(csv_file_path) \n",
    "    df_in = class_error(df_in) \n",
    "    df_in = duplicates(df_in)\n",
    "    csv_file_path = save_dataframe_to_csv(df_in, csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "csv_file_path = 'E:/Edited_20230310_SM_Lek1_P1D1_DJI_0158.csv'\n",
    "clean_annotation(csv_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
